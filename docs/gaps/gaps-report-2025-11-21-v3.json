{
  "project_name": "mcp-core-inventory",
  "project_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory",
  "timestamp": "2025-11-21 21:17:06",
  "validator_version": "9.4",
  "critical": [
    {
      "type": "No Code Conflicts",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Conflitos de declaracao detectados",
      "suggestion": "Remova ou renomeie as declaracoes duplicadas",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": true,
        "requires_review": true,
        "manual_steps": "1. Identifique qual declaracao manter\n2. Remova ou renomeie as duplicatas\n3. Atualize referencias",
        "non_fixable_reason": "ARCHITECTURAL",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "15-30 minutos",
        "confidence": 0
      },
      "examples": [
        "cli: 'init' declarado em ai.go, generate.go, monitor.go, root.go, state.go, template.go, version.go",
        "encryption: 'Manager' declarado em certificate_manager.go, encryption_manager.go, key_manager.go",
        "protocol: 'parseParams' declarado em handlers.go, router.go",
        "analytics: 'init' declarado em metrics.go, performance.go",
        "crush: 'max' declarado em batch_processor.go, parallel_processor.go",
        "crush: 'min' declarado em batch_processor.go, parallel_processor.go"
      ],
      "non_fixable_reason": "ARCHITECTURAL",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\generate.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"MCP project generation initiated\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(generateCmd)\n    46 | \tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n    47 | \tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n    48 | \tgenerateCmd.MarkFlagRequired(\"template\")\n    49 | }\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(generateCmd)\n\tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n\tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n\tgenerateCmd.MarkFlagRequired(\"template\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\monitor.go",
          "line_number": 24,
          "code_snippet": "    19 | \t\tcmd.Println(\"System status: Operational\")\n    20 | \t\treturn nil\n    21 | \t},\n    22 | }\n    23 | \nâ†’   24 | func init() {\n    25 | \trootCmd.AddCommand(monitorCmd)\n    26 | }\n    27 | \n    28 | // SetMonitoringService sets the monitoring service\n    29 | func SetMonitoringService(service *services.MonitoringAppService) {\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(monitorCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\root.go",
          "line_number": 39,
          "code_snippet": "    34 | \t\tos.Exit(1)\n    35 | \t}\n    36 | }\n    37 | \n    38 | // init initializes the CLI\nâ†’   39 | func init() {\n    40 | \trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n    41 | \trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n    42 | \n    43 | \t// Add subcommand groups\n    44 | \trootCmd.AddCommand(analytics.AnalyticsCmd)\n",
          "full_function": "func init() {\n\trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n\trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n\n\t// Add subcommand groups\n\trootCmd.AddCommand(analytics.AnalyticsCmd)\n\trootCmd.AddCommand(ci.CICmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "os",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/analytics",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/ci",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\state.go",
          "line_number": 20,
          "code_snippet": "    15 | \t\tcmd.Println(\"State management - service implementation pending\")\n    16 | \t\treturn nil\n    17 | \t},\n    18 | }\n    19 | \nâ†’   20 | func init() {\n    21 | \trootCmd.AddCommand(stateCmd)\n    22 | }\n    23 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(stateCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\template.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"Template created\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(templateCmd)\n    46 | \ttemplateCmd.AddCommand(templateListCmd)\n    47 | \ttemplateCmd.AddCommand(templateCreateCmd)\n    48 | \ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n    49 | \ttemplateCreateCmd.MarkFlagRequired(\"name\")\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(templateCmd)\n\ttemplateCmd.AddCommand(templateListCmd)\n\ttemplateCmd.AddCommand(templateCreateCmd)\n\ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n\ttemplateCreateCmd.MarkFlagRequired(\"name\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\version.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\tfmt.Printf(\"Version: %s\\n\", Version)\n    17 | \t\tfmt.Printf(\"Build Date: %s\\n\", BuildDate)\n    18 | \t},\n    19 | }\n    20 | \nâ†’   21 | func init() {\n    22 | \trootCmd.AddCommand(versionCmd)\n    23 | }\n    24 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(versionCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "parseParams",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\analytics\\performance.go",
          "line_number": 23,
          "code_snippet": "    18 | \t\tcmd.Println(\"  P95 Latency: 0ms\")\n    19 | \t\treturn nil\n    20 | \t},\n    21 | }\n    22 | \nâ†’   23 | func init() {\n    24 | \tAnalyticsCmd.AddCommand(performanceCmd)\n    25 | }\n    26 | \n",
          "full_function": "func init() {\n\tAnalyticsCmd.AddCommand(performanceCmd)\n}",
          "symbol_name": "init",
          "package_name": "analytics",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "min",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "10-30 minutos",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "Codigo compila",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Nao compila: # github.com/vertikon/mcp-core-inventory/internal/mcp/protocol\ninternal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used\ninternal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in thi...",
      "suggestion": "Corrija os erros de compilacao listados",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "non_fixable_reason": "BUSINESS_LOGIC",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "Variavel - depende dos erros",
        "confidence": 0
      },
      "examples": [
        "ðŸ“„ Log completo: E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\docs\\validation\\raw\\2025-11-21-21-15-18-compilation.log",
        "",
        "# github.com/vertikon/mcp-core-inventory/internal/mcp/protocol",
        "internal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in this block",
        "\tinternal\\mcp\\protocol\\handlers.go:779:6: other declaration of parseParams",
        "internal\\mcp\\protocol\\tools.go:358:64: undefined: protocol",
        "internal\\mcp\\protocol\\handlers.go:8:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\handlers.go:345:4: h.parseParams undefined (type *ListTemplatesHandler has no field or method parseParams)",
        "internal\\mcp\\protocol\\handlers.go:447:4: h.parseParams undefined (type *ListProjectsHandler has no field or method parseParams)",
        "# github.com/vertikon/mcp-core-inventory/tools/generators",
        "tools\\generators\\mcp_generator.go:6:2: \"path/filepath\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/cmd/core-inventory",
        "cmd\\core-inventory\\main.go:17:2: nats redeclared in this block",
        "\tcmd\\core-inventory\\main.go:16:2: other declaration of nats",
        "cmd\\core-inventory\\main.go:19:2: redis redeclared in this block",
        "\tcmd\\core-inventory\\main.go:14:2: other declaration of redis",
        "cmd\\core-inventory\\main.go:21:2: http redeclared in this block",
        "\tcmd\\core-inventory\\main.go:8:2: other declaration of http",
        "cmd\\core-inventory\\main.go:90:22: undefined: redis.NewStockCache",
        "cmd\\core-inventory\\main.go:91:27: undefined: redis.NewReservationLock",
        "cmd\\core-inventory\\main.go:92:19: undefined: nats.NewEventPublisher",
        "cmd\\core-inventory\\main.go:104:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewConfirmReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:111:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewReleaseReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:117:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.MovementRepository value in argument to app.NewAdjustStockUseCase: *postgres.LedgerRepository does not implement app.MovementRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.StockMovement) error",
        "cmd\\core-inventory\\main.go:143:17: undefined: http.NewRouter",
        "cmd\\core-inventory\\main.go:143:17: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/crush",
        "internal\\core\\crush\\parallel_processor.go:625:6: min redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:796:6: other declaration of min",
        "internal\\core\\crush\\parallel_processor.go:632:6: max redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:803:6: other declaration of max",
        "internal\\core\\crush\\batch_processor.go:269:19: undefined: runtime",
        "internal\\core\\crush\\batch_processor.go:427:6: declared and not used: id",
        "internal\\core\\crush\\batch_processor.go:560:18: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.AddInt64",
        "internal\\core\\crush\\batch_processor.go:584:42: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.LoadInt64",
        "internal\\core\\crush\\batch_processor.go:781:15: undefined: NewWorkerPool",
        "internal\\core\\crush\\batch_processor.go:792:23: too many arguments in call to abp.workerPool.Start",
        "\thave (context.Context)",
        "\twant ()",
        "internal\\core\\crush\\memory_optimizer.go:494:20: cannot use \u0026mo.stats.TotalMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: cannot use \u0026mo.stats.UsedMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/state",
        "internal\\core\\state\\distributed_store.go:543:22: invalid operation: cannot take address of dss.stats.LockWaitTime.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:649:31: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:651:21: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:656:31: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:658:21: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\store.go:10:2: \"github.com/vertikon/mcp-core-inventory/pkg/logger\" imported and not used",
        "internal\\core\\state\\store.go:11:2: \"go.uber.org/zap\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/core/transformer",
        "internal\\core\\transformer\\feedforward.go:194:21: ffn.router undefined (type *FeedForwardNetwork has no field or method router)",
        "internal\\core\\transformer\\transformer.go:152:38: not enough arguments in call to t.embeddings.Forward",
        "\thave (*Tensor)",
        "\twant (context.Context, *Tensor)",
        "internal\\core\\transformer\\transformer.go:209:79: cannot use attentionMask (variable of type *Tensor) as *AttentionMask value in argument to l.attention.Forward",
        "internal\\core\\transformer\\transformer.go:215:28: cannot use attnOutput (variable of type *AttentionResult) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\transformer.go:249:65: cannot use ln.eps (variable of type float64) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\positional_encoding.go:6:2: \"fmt\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/infrastructure/persistence/relational",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:198:2: declared and not used: knowledge",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:203:9: undefined: knowledgePtr",
        "# github.com/vertikon/mcp-core-inventory/internal/state/cache",
        "internal\\state\\cache\\cache_coherency.go:162:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "internal\\state\\cache\\cache_coherency.go:217:11: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:253:34: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:342:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "# github.com/vertikon/mcp-core-inventory/internal/security/encryption",
        "internal\\security\\encryption\\encryption_manager.go:56:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\encryption_manager.go:64:3: unknown field keyManager in struct literal of type Manager",
        "internal\\security\\encryption\\encryption_manager.go:71:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\encryption_manager.go:81:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\key_manager.go:52:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\key_manager.go:72:3: unknown field keyVersion in struct literal of type Manager",
        "internal\\security\\encryption\\key_manager.go:82:6: km.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:96:4: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:97:10: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:99:7: m.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:99:7: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/store",
        "internal\\state\\store\\conflict_resolver.go:236:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:238:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:251:2: declared and not used: localTime",
        "internal\\state\\store\\conflict_resolver.go:252:2: declared and not used: remoteTime",
        "internal\\state\\store\\conflict_resolver.go:283:51: too many arguments in call to r.isMergeableValue",
        "\thave (interface{}, interface{})",
        "\twant (interface{})",
        "internal\\state\\store\\conflict_resolver.go:396:9: v declared and not used",
        "internal\\state\\store\\conflict_resolver.go:415:13: r.mergeMaps undefined (type map[string]interface{} has no field or method mergeMaps)",
        "internal\\state\\store\\conflict_resolver.go:419:13: r.mergeArrays undefined (type []interface{} has no field or method mergeArrays)",
        "internal\\state\\store\\conflict_resolver.go:516:35: cannot use localTS (variable of struct type time.Time) as uint64 value in argument to max",
        "internal\\state\\store\\conflict_resolver.go:622:6: max redeclared in this block",
        "\tinternal\\state\\store\\conflict_resolver.go:615:6: other declaration of max",
        "internal\\state\\store\\conflict_resolver.go:516:35: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/events",
        "internal\\state\\events\\event_replay.go:249:2: declared and not used: snapshot",
        "internal\\state\\events\\event_replay.go:290:2: declared and not used: events",
        "internal\\state\\events\\event_versioning.go:140:4: invalid operation: cannot call copy (variable of struct type VersionInfo): VersionInfo is not a function",
        "internal\\state\\events\\event_versioning.go:216:30: ev.resolveVersionConflict undefined (type *EventVersioningImpl has no field or method resolveVersionConflict, but does have method ResolveVersionConflict)",
        ""
      ],
      "non_fixable_reason": "BUSINESS_LOGIC",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 6,
          "code_snippet": "     1 | package protocol\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"strings\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n     9 | \t\"go.uber.org/zap\"\n    10 | )\n    11 | \n",
          "full_function": "\t\"strings\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// ToolRouter handles routing of MCP tool requests to appropriate handlers\ntype ToolRouter struct {\n\thandlers map[string]ToolHandler\n\tlogger   *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\mcp\\protocol\\handlers.go",
          "line_number": 779,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\tools.go",
          "line_number": 358,
          "code_snippet": "   353 | func (h *ToolHandlerImpl) Schema() map[string]interface{} {\n   354 | \treturn h.schema\n   355 | }\n   356 | \n   357 | // Handle processes the tool request\nâ†’  358 | func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n   359 | \th.logger.Info(\"Handling tool request\",\n   360 | \t\tzap.String(\"tool\", h.name),\n   361 | \t\tzap.Any(\"params\", request.Params))\n   362 | \n   363 | \t// This is a placeholder implementation\n",
          "full_function": "func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n\th.logger.Info(\"Handling tool request\",\n\t\tzap.String(\"tool\", h.name),\n\t\tzap.Any(\"params\", request.Params))\n\n\t// This is a placeholder implementation\n\t// In a real implementation, each tool would have its own handler logic\n\tresult := map[string]interface{}{\n\t\t\"tool\":    h.name,\n\t\t\"status\":  \"implemented\",\n\t\t\"message\": fmt.Sprintf(\"Tool %s is ready for implementation\", h.name),\n\t}\n\n\treturn NewSuccessResponse(request.ID, result), nil\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 8,
          "code_snippet": "     3 | import (\n     4 | \t\"context\"\n     5 | \t\"encoding/json\"\n     6 | \t\"fmt\"\n     7 | \t\"os\"\nâ†’    8 | \t\"strings\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n    12 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n    13 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n",
          "full_function": "\t\"strings\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// HandlerManager manages all MCP tool handlers\ntype HandlerManager struct {\n\tgeneratorFactory *generators.GeneratorFactory\n\tvalidatorFactory *validators.ValidatorFactory\n\tregistry         *registry.MCPRegistry\n\tlogger           *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 345,
          "code_snippet": "   340 | \tvar params struct {\n   341 | \t\tStack    string `json:\"stack,omitempty\"`\n   342 | \t\tCategory string `json:\"category,omitempty\"`\n   343 | \t}\n   344 | \nâ†’  345 | \th.parseParams(request.Params, \u0026params)\n   346 | \n   347 | \ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n   348 | \t\tStack:    params.Stack,\n   349 | \t\tCategory: params.Category,\n   350 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n\t\tStack:    params.Stack,\n\t\tCategory: params.Category,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 447,
          "code_snippet": "   442 | \tvar params struct {\n   443 | \t\tStack  string `json:\"stack,omitempty\"`\n   444 | \t\tStatus string `json:\"status,omitempty\"`\n   445 | \t}\n   446 | \nâ†’  447 | \th.parseParams(request.Params, \u0026params)\n   448 | \n   449 | \tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n   450 | \t\tStack:  params.Stack,\n   451 | \t\tStatus: params.Status,\n   452 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n\t\tStack:  params.Stack,\n\t\tStatus: params.Status,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\tools\\generators\\mcp_generator.go",
          "line_number": 6,
          "code_snippet": "     1 | package generators\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"path/filepath\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n     9 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    10 | \t\"go.uber.org/zap\"\n    11 | )\n",
          "full_function": "\t\"path/filepath\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// MCPGenerator orchestrates MCP generation using internal/mcp/generators\n// This is the CLI/Tool interface for generating MCPs\ntype MCPGenerator struct {\n\tfactory *generators.GeneratorFactory\n\tlogger  *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "generators",
          "dependencies": [
            "context",
            "fmt",
            "path/filepath",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 17,
          "code_snippet": "    12 | \t\"time\"\n    13 | \n    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\nâ†’   17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 16,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 19,
          "code_snippet": "    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\nâ†’   19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 14,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\nâ†’   21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    25 | \t\"go.uber.org/zap\"\n    26 | )\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 8,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 90,
          "code_snippet": "    85 | \t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\nâ†’   90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 91,
          "code_snippet": "    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\nâ†’   91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 92,
          "code_snippet": "    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\nâ†’   92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n    97 | \t\treservationLock,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 104,
          "code_snippet": "    99 | \t\tlogger.GetLogger(),\n   100 | \t)\n   101 | \n   102 | \tconfirmUseCase := app.NewConfirmReservationUseCase(\n   103 | \t\tledgerRepo,\nâ†’  104 | \t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n   105 | \t\teventPub,\n   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 111,
          "code_snippet": "   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n   110 | \t\tledgerRepo,\nâ†’  111 | \t\tledgerRepo,\n   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 117,
          "code_snippet": "   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\nâ†’  117 | \t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n   118 | \t\tlogger.GetLogger(),\n   119 | \t)\n   120 | \n   121 | \tqueryUseCase := app.NewQueryAvailableUseCase(\n   122 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 796,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 803,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 269,
          "code_snippet": "   264 | \n   265 | \t// Initialize async processor\n   266 | \tif config.EnableAsync {\n   267 | \t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n   268 | \t\t\tEnabled:       true,\nâ†’  269 | \t\t\tNumWorkers:    runtime.NumCPU(),\n   270 | \t\t\tQueueSize:     100,\n   271 | \t\t\tWorkerTimeout: config.Timeout,\n   272 | \t\t\tRetryAttempts: 3,\n   273 | \t\t})\n   274 | \t}\n",
          "full_function": "func NewBatchProcessor(config BatchProcessorConfig) *BatchProcessor {\n\tif config.MaxBatchSize == 0 {\n\t\tconfig.MaxBatchSize = 32\n\t}\n\tif config.MinBatchSize == 0 {\n\t\tconfig.MinBatchSize = 1\n\t}\n\tif config.Timeout == 0 {\n\t\tconfig.Timeout = 5 * time.Second\n\t}\n\n\tlogger.Info(\"Creating batch processor\",\n\t\tzap.Int(\"max_batch_size\", config.MaxBatchSize),\n\t\tzap.Int(\"min_batch_size\", config.MinBatchSize),\n\t\tzap.Duration(\"timeout\", config.Timeout),\n\t\tzap.Bool(\"dynamic_batching\", config.EnableDynamicBatching),\n\t\tzap.Bool(\"prefetch\", config.EnablePrefetch),\n\t\tzap.Bool(\"async\", config.EnableAsync),\n\t)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\n\tprocessor := \u0026BatchProcessor{\n\t\tconfig:      config,\n\t\tbatches:     make(map[string]*Batch),\n\t\tbatchQueue:  make(chan *Batch, 100),\n\t\tresultQueue: make(chan *BatchResult, 100),\n\t\tctx:         ctx,\n\t\tcancel:      cancel,\n\t\tstats:       \u0026BatchProcessorStats{},\n\t}\n\n\t// Initialize dynamic sizing\n\tif config.EnableDynamicBatching {\n\t\tprocessor.dynamicSizing = NewDynamicBatchSizer(DynamicSizingConfig{\n\t\t\tEnabled:       true,\n\t\t\tStrategy:      StrategyAdaptive,\n\t\t\tMinSize:       config.MinBatchSize,\n\t\t\tMaxSize:       config.MaxBatchSize,\n\t\t\tTargetLatency: config.MaxLatency,\n\t\t})\n\t}\n\n\t// Initialize prefetcher\n\tif config.EnablePrefetch {\n\t\tprocessor.prefetcher = NewBatchPrefetcher(PrefetchConfig{\n\t\t\tEnabled:        true,\n\t\t\tPrefetchSize:   config.MaxBatchSize,\n\t\t\tCacheSize:      100,\n\t\t\tPrefetchPolicy: PolicyPredictive,\n\t\t})\n\t}\n\n\t// Initialize async processor\n\tif config.EnableAsync {\n\t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n\t\t\tEnabled:       true,\n\t\t\tNumWorkers:    runtime.NumCPU(),\n\t\t\tQueueSize:     100,\n\t\t\tWorkerTimeout: config.Timeout,\n\t\t\tRetryAttempts: 3,\n\t\t})\n\t}\n\n\treturn processor\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 427,
          "code_snippet": "   422 | func (bp *BatchProcessor) checkBatchTimeouts() {\n   423 | \tbp.mu.Lock()\n   424 | \tdefer bp.mu.Unlock()\n   425 | \n   426 | \tnow := time.Now()\nâ†’  427 | \tfor id, batch := range bp.batches {\n   428 | \t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n   429 | \t\t\tbp.submitBatch(batch)\n   430 | \t\t}\n   431 | \t}\n   432 | }\n",
          "full_function": "func (bp *BatchProcessor) checkBatchTimeouts() {\n\tbp.mu.Lock()\n\tdefer bp.mu.Unlock()\n\n\tnow := time.Now()\n\tfor id, batch := range bp.batches {\n\t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n\t\t\tbp.submitBatch(batch)\n\t\t}\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 560,
          "code_snippet": "   555 | // updateStats updates batch processing statistics\n   556 | func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n   557 | \tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n   558 | \tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n   559 | \tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\nâ†’  560 | \tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n   561 | \n   562 | \tif len(result.Errors) \u003e 0 {\n   563 | \t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n   564 | \t}\n   565 | }\n",
          "full_function": "func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n\tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n\tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n\n\tif len(result.Errors) \u003e 0 {\n\t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 584,
          "code_snippet": "   579 | \t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n   580 | \t}\n   581 | \n   582 | \t// Calculate average processing time\n   583 | \tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\nâ†’  584 | \ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n   585 | \n   586 | \tif completedBatches \u003e 0 {\n   587 | \t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n   588 | \t}\n   589 | \n",
          "full_function": "func (bp *BatchProcessor) collectStats() {\n\tbp.stats.LastUpdated = time.Now()\n\n\t// Calculate queue utilization\n\tbp.stats.QueueUtilization = float64(len(bp.batchQueue)) / float64(cap(bp.batchQueue))\n\n\t// Calculate average batch size\n\ttotalBatches := atomic.LoadInt64(\u0026bp.stats.TotalBatches)\n\ttotalItems := atomic.LoadInt64(\u0026bp.stats.TotalItems)\n\n\tif totalBatches \u003e 0 {\n\t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n\t}\n\n\t// Calculate average processing time\n\tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\n\ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n\t}\n\n\t// Calculate throughput\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.Throughput = float64(totalItems) / time.Since(time.Now()).Seconds()\n\t}\n\n\tlogger.Debug(\"Batch processor stats\",\n\t\tzap.Float64(\"queue_utilization\", bp.stats.QueueUtilization),\n\t\tzap.Float64(\"avg_batch_size\", bp.stats.AvgBatchSize),\n\t\tzap.Duration(\"avg_processing_time\", bp.stats.AvgProcessingTime),\n\t\tzap.Float64(\"throughput\", bp.stats.Throughput),\n\t)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 781,
          "code_snippet": "   776 | \n   777 | // NewAsyncBatchProcessor creates a new async batch processor\n   778 | func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n   779 | \treturn \u0026AsyncBatchProcessor{\n   780 | \t\tconfig:     config,\nâ†’  781 | \t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n   782 | \t\tstats:      \u0026AsyncProcessingStats{},\n   783 | \t}\n   784 | }\n   785 | \n   786 | // Start starts async batch processor\n",
          "full_function": "func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n\treturn \u0026AsyncBatchProcessor{\n\t\tconfig:     config,\n\t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n\t\tstats:      \u0026AsyncProcessingStats{},\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 792,
          "code_snippet": "   787 | func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n   788 | \tif !abp.config.Enabled {\n   789 | \t\treturn\n   790 | \t}\n   791 | \nâ†’  792 | \tabp.workerPool.Start(ctx)\n   793 | }\n   794 | \n   795 | // Additional helper functions\n   796 | func min(a, b int) int {\n   797 | \tif a \u003c b {\n",
          "full_function": "func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n\tif !abp.config.Enabled {\n\t\treturn\n\t}\n\n\tabp.workerPool.Start(ctx)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 494,
          "code_snippet": "   489 | \t\ttotalMemory += segment.Size\n   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \nâ†’  494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n   495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 543,
          "code_snippet": "   538 | \t}\n   539 | \n   540 | \tstart := time.Now()\n   541 | \tdefer func() {\n   542 | \t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\nâ†’  543 | \t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n   544 | \t}()\n   545 | \n   546 | \t// Try remote store first\n   547 | \tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n   548 | \tif err == nil {\n",
          "full_function": "func (dss *DistributedStateStore) Lock(ctx context.Context, key string, ttl time.Duration) (*Lock, error) {\n\tif !dss.config.EnableLocking {\n\t\treturn nil, fmt.Errorf(\"locking is not enabled\")\n\t}\n\n\tstart := time.Now()\n\tdefer func() {\n\t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\n\t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n\t}()\n\n\t// Try remote store first\n\tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n\tif err == nil {\n\t\treturn lock, nil\n\t}\n\n\t// Fallback to local store\n\treturn dss.localStore.Lock(ctx, key, ttl)\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 649,
          "code_snippet": "   644 | \treturn *dss.stats\n   645 | }\n   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\nâ†’  649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 651,
          "code_snippet": "   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n   649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 656,
          "code_snippet": "   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\nâ†’  656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 658,
          "code_snippet": "   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n   662 | func NewMemoryStateStore() *MemoryStateStore {\n   663 | \treturn \u0026MemoryStateStore{\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 10,
          "code_snippet": "     5 | \t\"context\"\n     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\nâ†’   10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 11,
          "code_snippet": "     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\n    10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\nâ†’   11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n    16 | \tdb *badger.DB\n",
          "full_function": "\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\feedforward.go",
          "line_number": 194,
          "code_snippet": "   189 | }\n   190 | \n   191 | // forwardMoE performs mixture of experts computation\n   192 | func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n   193 | \t// Router determines which experts to use\nâ†’  194 | \trouter, err := ffn.router.Forward(input)\n   195 | \tif err != nil {\n   196 | \t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n   197 | \t}\n   198 | \n   199 | \t// Select top-k experts\n",
          "full_function": "func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n\t// Router determines which experts to use\n\trouter, err := ffn.router.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n\t}\n\n\t// Select top-k experts\n\tselectedExperts := ffn.selectTopKExperts(router)\n\n\t// Combine expert outputs\n\toutput := ffn.combineExperts(input, selectedExperts)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 152,
          "code_snippet": "   147 | \t\treturn nil, ctx.Err()\n   148 | \tdefault:\n   149 | \t}\n   150 | \n   151 | \t// Embedding layer\nâ†’  152 | \thidden, err := t.embeddings.Forward(input)\n   153 | \tif err != nil {\n   154 | \t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n   155 | \t}\n   156 | \n   157 | \t// Add positional encoding\n",
          "full_function": "func (t *GLMTransformer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tt.mu.RLock()\n\tdefer t.mu.RUnlock()\n\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Embedding layer\n\thidden, err := t.embeddings.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n\t}\n\n\t// Add positional encoding\n\tif t.posEncoding != nil {\n\t\tposEncoded, err := t.posEncoding.Forward(ctx, hidden, 0)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"positional encoding error: %w\", err)\n\t\t}\n\t\thidden = posEncoded\n\t}\n\n\t// Pass through transformer layers\n\tfor i, layer := range t.layers {\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tlayerOutput, err := layer.Forward(ctx, hidden, attentionMask)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"layer %d error: %w\", i, err)\n\t\t}\n\t\thidden = layerOutput\n\n\t\tlogger.Debug(\"Transformer layer processed\",\n\t\t\tzap.Int(\"layer\", i),\n\t\t\tzap.Float64(\"mean_activation\", t.meanActivation(hidden)),\n\t\t)\n\t}\n\n\t// Final layer norm\n\toutput, err := t.layernorm.Forward(hidden)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"final layer norm error: %w\", err)\n\t}\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 209,
          "code_snippet": "   204 | \tnormInput, err := l.layernorm1.Forward(input)\n   205 | \tif err != nil {\n   206 | \t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n   207 | \t}\n   208 | \nâ†’  209 | \tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 215,
          "code_snippet": "   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\nâ†’  215 | \tresidual1 := t.add(input, attnOutput)\n   216 | \n   217 | \t// Pre-norm + feed-forward\n   218 | \tnormResidual, err := l.layernorm2.Forward(residual1)\n   219 | \tif err != nil {\n   220 | \t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 249,
          "code_snippet": "   244 | // Forward performs layer normalization\n   245 | func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n   246 | \t// Simplified layer norm implementation\n   247 | \tmean := t.mean(input, -1, true)\n   248 | \tvariance := t.variance(input, -1, true)\nâ†’  249 | \tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n   250 | \n   251 | \t// Scale and shift\n   252 | \toutput := t.mul(normalized, ln.weight)\n   253 | \toutput = t.add(output, ln.bias)\n   254 | \n",
          "full_function": "func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n\t// Simplified layer norm implementation\n\tmean := t.mean(input, -1, true)\n\tvariance := t.variance(input, -1, true)\n\tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n\n\t// Scale and shift\n\toutput := t.mul(normalized, ln.weight)\n\toutput = t.add(output, ln.bias)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\positional_encoding.go",
          "line_number": 6,
          "code_snippet": "     1 | // Package transformer implements positional encoding for GLM-4.6\n     2 | package transformer\n     3 | \n     4 | import (\n     5 | \t\"context\"\nâ†’    6 | \t\"fmt\"\n     7 | \t\"math\"\n     8 | \t\"sync\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"fmt\"\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// PositionalEncodingType represents different positional encoding approaches\ntype PositionalEncodingType string\n\nconst (\n\tPosEncodingTypeSinusoidal PositionalEncodingType = \"sinusoidal\"\n\tPosEncodingTypeLearned    PositionalEncodingType = \"learned\"\n\tPosEncodingTypeRelative   PositionalEncodingType = \"relative\"\n\tPosEncodingTypeRotary     PositionalEncodingType = \"rotary\"\n\tPosEncodingTypeALiBi      PositionalEncodingType = \"alibi\"\n\tPosEncodingTypeXPos       PositionalEncodingType = \"xpos\"\n)\n\n// PositionalEncodingConfig represents positional encoding configuration\ntype PositionalEncodingConfig struct {\n\tType        PositionalEncodingType `json:\"type\"`\n\tMaxSeqLen   int                    `json:\"max_seq_len\"`\n\tHiddenSize  int                    `json:\"hidden_size\"`\n\tHeadDim     int                    `json:\"head_dim,omitempty\"`\n\tBase        float64                `json:\"base\"`\n\tScale       bool                   `json:\"scale\"`\n\tNormalize   bool                   `json:\"normalize\"`\n\tConcatenate bool                   `json:\"concatenate\"`\n\tRotateHalf  bool                   `json:\"rotate_half\"`\n\tUseRoPE     bool                   `json:\"use_rope\"`\n\tUseXPos     bool                   `json:\"use_xpos\"`\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 198,
          "code_snippet": "   193 | \t}\n   194 | \tif err != nil {\n   195 | \t\treturn nil, fmt.Errorf(\"failed to find Knowledge: %w\", err)\n   196 | \t}\n   197 | \nâ†’  198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \n   203 | \treturn knowledgePtr, nil\n",
          "full_function": "\tknowledge, err := entities.NewKnowledge(name, description)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n\t}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 203,
          "code_snippet": "   198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \nâ†’  203 | \treturn knowledgePtr, nil\n   204 | }\n   205 | \n   206 | // List lists all Knowledge entities with optional filters\n   207 | func (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n   208 | \tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n",
          "full_function": "\treturn knowledgePtr, nil\n}\n\n// List lists all Knowledge entities with optional filters\nfunc (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n\tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n\targs := []interface{}{}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 162,
          "code_snippet": "   157 | \tcm.stats.TotalInvalidations++\n   158 | \tcm.stats.InvalidationsByReason[reason]++\n   159 | \tcm.mu.Unlock()\n   160 | \n   161 | \t// Delete from cache\nâ†’  162 | \tcm.cache.Delete(key)\n   163 | \n   164 | \t// Create invalidation event\n   165 | \tevent := \u0026InvalidationEvent{\n   166 | \t\tKey:       key,\n   167 | \t\tReason:    reason,\n",
          "full_function": "func (cm *CoherencyManagerImpl) Invalidate(ctx context.Context, key string, reason string) error {\n\tstart := time.Now()\n\n\tcm.mu.Lock()\n\tcm.stats.TotalInvalidations++\n\tcm.stats.InvalidationsByReason[reason]++\n\tcm.mu.Unlock()\n\n\t// Delete from cache\n\tcm.cache.Delete(key)\n\n\t// Create invalidation event\n\tevent := \u0026InvalidationEvent{\n\t\tKey:       key,\n\t\tReason:    reason,\n\t\tTimestamp: time.Now(),\n\t\tSource:    \"coherency_manager\",\n\t}\n\n\t// Send to invalidation channel\n\tselect {\n\tcase cm.invalidationCh \u003c- event:\n\tdefault:\n\t\tcm.logger.Warn(\"Invalidation channel full, dropping event\",\n\t\t\tzap.String(\"key\", key))\n\t}\n\n\tcm.mu.Lock()\n\tcm.stats.AverageInvalidationTime = time.Since(start)\n\tlastTime := time.Now()\n\tcm.stats.LastInvalidation = \u0026lastTime\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Cache key invalidated\",\n\t\tzap.String(\"key\", key),\n\t\tzap.String(\"reason\", reason))\n\n\treturn nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 217,
          "code_snippet": "   212 | }\n   213 | \n   214 | // Update updates a cache entry\n   215 | func (cm *CoherencyManagerImpl) Update(ctx context.Context, key string, value interface{}) error {\n   216 | \tcm.mu.Lock()\nâ†’  217 | \tcm.stats.TotalUpdates++\n   218 | \tcm.mu.Unlock()\n   219 | \n   220 | \t// Update cache based on strategy\n   221 | \tswitch cm.config.Strategy {\n   222 | \tcase CoherencyStrategyWriteThrough:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 253,
          "code_snippet": "   248 | \t\tStrategy:             cm.config.Strategy,\n   249 | \t\tLevel:                cm.config.Level,\n   250 | \t\tIsCoherent:           true, // Simplified\n   251 | \t\tPendingInvalidations: len(cm.pendingInvalidations),\n   252 | \t\tTotalInvalidations:   cm.stats.TotalInvalidations,\nâ†’  253 | \t\tTotalUpdates:         cm.stats.TotalUpdates,\n   254 | \t}, nil\n   255 | }\n   256 | \n   257 | // GetInvalidationStats returns invalidation statistics\n   258 | func (cm *CoherencyManagerImpl) GetInvalidationStats(ctx context.Context) (*InvalidationStats, error) {\n",
          "full_function": "func (cm *CoherencyManagerImpl) GetCoherencyStatus(ctx context.Context) (*CoherencyStatus, error) {\n\tcm.mu.RLock()\n\tdefer cm.mu.RUnlock()\n\n\treturn \u0026CoherencyStatus{\n\t\tStrategy:             cm.config.Strategy,\n\t\tLevel:                cm.config.Level,\n\t\tIsCoherent:           true, // Simplified\n\t\tPendingInvalidations: len(cm.pendingInvalidations),\n\t\tTotalInvalidations:   cm.stats.TotalInvalidations,\n\t\tTotalUpdates:         cm.stats.TotalUpdates,\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 342,
          "code_snippet": "   337 | \tcm.mu.Lock()\n   338 | \tcm.pendingInvalidations[event.Key] = event\n   339 | \tcm.mu.Unlock()\n   340 | \n   341 | \t// Process invalidation\nâ†’  342 | \tcm.cache.Delete(event.Key)\n   343 | \n   344 | \tcm.mu.Lock()\n   345 | \tdelete(cm.pendingInvalidations, event.Key)\n   346 | \tcm.mu.Unlock()\n   347 | \n",
          "full_function": "func (cm *CoherencyManagerImpl) processInvalidation(event *InvalidationEvent) {\n\tcm.mu.Lock()\n\tcm.pendingInvalidations[event.Key] = event\n\tcm.mu.Unlock()\n\n\t// Process invalidation\n\tcm.cache.Delete(event.Key)\n\n\tcm.mu.Lock()\n\tdelete(cm.pendingInvalidations, event.Key)\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Invalidation processed\",\n\t\tzap.String(\"key\", event.Key),\n\t\tzap.String(\"reason\", event.Reason))\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 64,
          "code_snippet": "    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n    62 | func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n    63 | \treturn \u0026Manager{\nâ†’   64 | \t\tkeyManager: keyManager,\n    65 | \t\tlogger:     logger.WithContext(nil),\n    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n",
          "full_function": "func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n\treturn \u0026Manager{\n\t\tkeyManager: keyManager,\n\t\tlogger:     logger.WithContext(nil),\n\t}\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 71,
          "code_snippet": "    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n    70 | func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\nâ†’   71 | \tkey, err := m.keyManager.GetEncryptionKey()\n    72 | \tif err != nil {\n    73 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    74 | \t\treturn nil, err\n    75 | \t}\n    76 | \treturn m.EncryptWithKey(plaintext, key)\n",
          "full_function": "func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.EncryptWithKey(plaintext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 81,
          "code_snippet": "    76 | \treturn m.EncryptWithKey(plaintext, key)\n    77 | }\n    78 | \n    79 | // Decrypt decrypts data using AES-256-GCM with default key\n    80 | func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\nâ†’   81 | \tkey, err := m.keyManager.GetEncryptionKey()\n    82 | \tif err != nil {\n    83 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    84 | \t\treturn nil, err\n    85 | \t}\n    86 | \treturn m.DecryptWithKey(ciphertext, key)\n",
          "full_function": "func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.DecryptWithKey(ciphertext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 72,
          "code_snippet": "    67 | }\n    68 | \n    69 | // NewKeyManager creates a new KeyManager\n    70 | func NewKeyManager(config KeyManagerConfig) KeyManager {\n    71 | \tkm := \u0026Manager{\nâ†’   72 | \t\tkeyVersion:  \"v1\",\n    73 | \t\trotationTTL: config.RotationTTL,\n    74 | \t\tlogger:      logger.WithContext(nil),\n    75 | \t}\n    76 | \n    77 | \t// Generate initial encryption key\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 82,
          "code_snippet": "    77 | \t// Generate initial encryption key\n    78 | \tkey := make([]byte, 32) // AES-256\n    79 | \tif _, err := rand.Read(key); err != nil {\n    80 | \t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n    81 | \t} else {\nâ†’   82 | \t\tkm.encryptionKey = key\n    83 | \t}\n    84 | \n    85 | \t// Generate RSA key pair\n    86 | \tif err := km.generateRSAKeys(config.KeySize); err != nil {\n    87 | \t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 96,
          "code_snippet": "    91 | \treturn km\n    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\nâ†’   96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 97,
          "code_snippet": "    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\nâ†’   97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 236,
          "code_snippet": "   231 | \t// Compare vector clocks\n   232 | \tcomparison := r.compareVectorClocks(localVC, remoteVC)\n   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\nâ†’  236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\n   238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 238,
          "code_snippet": "   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\n   236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\nâ†’  238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n   242 | \tdefault:\n   243 | \t\t// Same vector clock, use timestamp as tie-breaker\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 251,
          "code_snippet": "   246 | }\n   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\nâ†’  251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\n   252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 252,
          "code_snippet": "   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\n   251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\nâ†’  252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n   257 | \n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 283,
          "code_snippet": "   278 | func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n   279 | \t// For simple values, use last-write-wins\n   280 | \t// For complex values (maps, sets, counters), perform actual CRDT merge\n   281 | \n   282 | \t// Check if values are mergeable\nâ†’  283 | \tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n   284 | \t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n   285 | \t\tif err != nil {\n   286 | \t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n   287 | \t\t\t\tzap.String(\"key\", conflict.Key),\n   288 | \t\t\t\tzap.Error(err))\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n\t// For simple values, use last-write-wins\n\t// For complex values (maps, sets, counters), perform actual CRDT merge\n\n\t// Check if values are mergeable\n\tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n\t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n\t\tif err != nil {\n\t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n\t\t\t\tzap.String(\"key\", conflict.Key),\n\t\t\t\tzap.Error(err))\n\t\t\treturn r.resolveCRDTLastWriterWins(conflict)\n\t\t}\n\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   mergedValue,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     r.mergeTTL(conflict.LocalState.TTL, conflict.RemoteState.TTL),\n\t\t\tMeta:    r.createCRDTMergeMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta),\n\t\t}, nil\n\t}\n\n\t// Non-mergeable, fall back to LWW\n\treturn r.resolveCRDTLastWriterWins(conflict)\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 396,
          "code_snippet": "   391 | \treturn ts\n   392 | }\n   393 | \n   394 | func (r *ConflictResolverImpl) isMergeableValue(value interface{}) bool {\n   395 | \t// Check if value is a type that can be merged\nâ†’  396 | \tswitch v := value.(type) {\n   397 | \tcase map[string]interface{}:\n   398 | \t\treturn true\n   399 | \tcase []interface{}:\n   400 | \t\treturn true\n   401 | \tcase map[string]string:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 415,
          "code_snippet": "   410 | func (r *ConflictResolverImpl) mergeValues(local, remote interface{}) (interface{}, error) {\n   411 | \t// Implement actual CRDT merge logic based on value type\n   412 | \tswitch l := local.(type) {\n   413 | \tcase map[string]interface{}:\n   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\nâ†’  415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\n   419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 419,
          "code_snippet": "   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\n   415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\nâ†’  419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n   421 | \t}\n   422 | \n   423 | \t// Cannot merge, return error\n   424 | \treturn nil, fmt.Errorf(\"values are not mergeable\")\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\state\\store\\conflict_resolver.go",
          "line_number": 615,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 249,
          "code_snippet": "   244 | }\n   245 | \n   246 | // ReplayFromSnapshot replays events from a snapshot version\n   247 | func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n   248 | \t// Get snapshot\nâ†’  249 | \tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n   250 | \tif err != nil {\n   251 | \t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n   252 | \t}\n   253 | \n   254 | \t// Get events after snapshot version\n",
          "full_function": "func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n\t// Get snapshot\n\tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n\t}\n\n\t// Get events after snapshot version\n\tevents, err := er.store.GetEvents(ctx, aggregateID, snapshotVersion+1, 0)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get events after snapshot: %w\", err)\n\t}\n\n\tif len(events) == 0 {\n\t\treturn \u0026ReplayProgress{\n\t\t\tTotalEvents:     0,\n\t\t\tProcessedEvents: 0,\n\t\t\tIsComplete:      true,\n\t\t}, nil\n\t}\n\n\tstartTime := time.Now()\n\tprogress := \u0026ReplayProgress{\n\t\tTotalEvents:    int64(len(events)),\n\t\tStartTime:      startTime,\n\t\tCurrentVersion: snapshotVersion + 1,\n\t}\n\n\terr = er.replaySequential(ctx, events, handler, progress)\n\tprogress.ElapsedTime = time.Since(startTime)\n\tprogress.IsComplete = true\n\n\tif err != nil {\n\t\tprogress.LastError = err.Error()\n\t\treturn progress, err\n\t}\n\n\treturn progress, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 290,
          "code_snippet": "   285 | }\n   286 | \n   287 | // ReplayToState replays events to rebuild state at a specific version\n   288 | func (er *EventReplayImpl) ReplayToState(ctx context.Context, aggregateID string, targetVersion int64, handler ReplayHandler) (interface{}, error) {\n   289 | \t// Get all events up to target version\nâ†’  290 | \tevents, err := er.store.GetEvents(ctx, aggregateID, 1, targetVersion)\n   291 | \tif err != nil {\n   292 | \t\treturn nil, fmt.Errorf(\"failed to get events: %w\", err)\n   293 | \t}\n   294 | \n   295 | \t// Replay events\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 140,
          "code_snippet": "   135 | \tif exists {\n   136 | \t\t// Return copy\n   137 | \t\tcopy := *versionInfo\n   138 | \t\tif versionInfo.VersionHistory != nil {\n   139 | \t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\nâ†’  140 | \t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n   141 | \t\t}\n   142 | \t\treturn \u0026copy, nil\n   143 | \t}\n   144 | \n   145 | \t// Load from event store\n",
          "full_function": "func (ev *EventVersioningImpl) GetVersion(ctx context.Context, aggregateID string) (*VersionInfo, error) {\n\tev.mu.RLock()\n\tversionInfo, exists := ev.versions[aggregateID]\n\tev.mu.RUnlock()\n\n\tif exists {\n\t\t// Return copy\n\t\tcopy := *versionInfo\n\t\tif versionInfo.VersionHistory != nil {\n\t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\n\t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n\t\t}\n\t\treturn \u0026copy, nil\n\t}\n\n\t// Load from event store\n\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t}\n\n\tversionInfo = \u0026VersionInfo{\n\t\tAggregateID:    aggregateID,\n\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\tCurrentVersion: aggregateInfo.Version,\n\t\tMetadata:       make(map[string]interface{}),\n\t}\n\n\tif ev.config.EnableHistory {\n\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t}\n\n\tev.mu.Lock()\n\tev.versions[aggregateID] = versionInfo\n\tev.mu.Unlock()\n\n\treturn versionInfo, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 216,
          "code_snippet": "   211 | \t\tif ev.config.ConflictResolution == \"reject\" {\n   212 | \t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n   213 | \t\t}\n   214 | \n   215 | \t\t// Resolve conflict\nâ†’  216 | \t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n   217 | \t\tif err != nil {\n   218 | \t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n   219 | \t\t}\n   220 | \n   221 | \t\tnewVersion = resolvedVersion\n",
          "full_function": "func (ev *EventVersioningImpl) IncrementVersion(ctx context.Context, aggregateID string, event *Event) (int64, error) {\n\tev.mu.Lock()\n\tdefer ev.mu.Unlock()\n\n\tversionInfo, exists := ev.versions[aggregateID]\n\tif !exists {\n\t\t// Load from store\n\t\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t\t}\n\n\t\tversionInfo = \u0026VersionInfo{\n\t\t\tAggregateID:    aggregateID,\n\t\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\t\tCurrentVersion: aggregateInfo.Version,\n\t\t\tMetadata:       make(map[string]interface{}),\n\t\t}\n\n\t\tif ev.config.EnableHistory {\n\t\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t\t}\n\n\t\tev.versions[aggregateID] = versionInfo\n\t}\n\n\t// Increment version\n\tnewVersion := versionInfo.CurrentVersion + 1\n\n\t// Validate version continuity\n\tif event.Version != 0 \u0026\u0026 event.Version != newVersion {\n\t\tconflict := \u0026VersionConflict{\n\t\t\tAggregateID:     aggregateID,\n\t\t\tExpectedVersion: newVersion,\n\t\t\tActualVersion:   event.Version,\n\t\t\tConflictTime:    time.Now(),\n\t\t}\n\n\t\tev.stats.TotalConflicts++\n\t\tev.conflicts[aggregateID] = append(ev.conflicts[aggregateID], conflict)\n\n\t\tif ev.config.ConflictResolution == \"reject\" {\n\t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n\t\t}\n\n\t\t// Resolve conflict\n\t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n\t\t}\n\n\t\tnewVersion = resolvedVersion\n\t\tconflict.Resolution = fmt.Sprintf(\"resolved to %d\", resolvedVersion)\n\t\tev.stats.ResolvedConflicts++\n\t}\n\n\t// Update version info\n\tversionInfo.CurrentVersion = newVersion\n\tversionInfo.LastEventID = event.ID\n\tversionInfo.LastEventTime = event.Timestamp\n\n\t// Add to history\n\tif ev.config.EnableHistory {\n\t\tentry := VersionHistoryEntry{\n\t\t\tVersion:   newVersion,\n\t\t\tEventID:   event.ID,\n\t\t\tTimestamp: event.Timestamp,\n\t\t\tEventType: event.Type,\n\t\t}\n\n\t\tversionInfo.VersionHistory = append(versionInfo.VersionHistory, entry)\n\n\t\t// Trim history if needed\n\t\tif len(versionInfo.VersionHistory) \u003e ev.config.HistoryRetention {\n\t\t\tversionInfo.VersionHistory = versionInfo.VersionHistory[len(versionInfo.VersionHistory)-ev.config.HistoryRetention:]\n\t\t}\n\t}\n\n\t// Update statistics\n\tev.stats.TotalVersions++\n\tev.stats.VersionDistribution[newVersion]++\n\n\tev.logger.Debug(\"Version incremented\",\n\t\tzap.String(\"aggregate_id\", aggregateID),\n\t\tzap.Int64(\"version\", newVersion))\n\n\treturn newVersion, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 25,
        "affected_lines": 83,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "1-2 horas",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "Nil Pointer Check",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "1 potencial(is) nil pointer issue(s)",
      "suggestion": "Adicione nil checks",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "tools": null,
        "executable_steps": null,
        "estimated_time": "",
        "confidence": 0
      },
      "examples": [
        "multi_level_cache.go:180"
      ],
      "code_contexts": null,
      "impact_analysis": {
        "severity": "",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "",
        "priority": 0,
        "risk_level": "",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    }
  ],
  "high": null,
  "medium": null,
  "low": [
    {
      "type": "Linter limpo",
      "severity": "low",
      "location": "multiplos arquivos",
      "description": "âœ— FAIL: 36 issues crÃ­ticos, 0 warnings",
      "suggestion": "Corrija os issues FAIL primeiro, depois warnings",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": true,
        "requires_review": true,
        "non_fixable_reason": "BUSINESS_LOGIC",
        "tools": [
          {
            "tool_name": "golangci-lint",
            "install_command": "go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest",
            "diagnose_command": "golangci-lint run",
            "fix_command": "# NAO use --fix automaticamente, revise cada issue",
            "config_required": true,
            "config_template": ".golangci.yml com linters selecionados",
            "documentation": "https://golangci-lint.run/",
            "alternative_tools": null
          },
          {
            "tool_name": "staticcheck",
            "install_command": "go install honnef.co/go/tools/cmd/staticcheck@latest",
            "diagnose_command": "staticcheck ./...",
            "fix_command": "# Manual - staticcheck nao tem auto-fix",
            "config_required": false,
            "config_template": "",
            "documentation": "https://staticcheck.io/",
            "alternative_tools": null
          },
          {
            "tool_name": "gosec",
            "install_command": "go install github.com/securego/gosec/v2/cmd/gosec@latest",
            "diagnose_command": "gosec ./...",
            "fix_command": "# Manual - corrija issues de seguranca",
            "config_required": false,
            "config_template": "",
            "documentation": "https://github.com/securego/gosec",
            "alternative_tools": null
          }
        ],
        "executable_steps": null,
        "estimated_time": "1h12m",
        "confidence": 0
      },
      "examples": [
        "ðŸ“¦ MÃ³dulos analisados: 1",
        "ðŸ“„ Linter Report v3: JSON + SARIF gerados",
        "",
        "ðŸ“Š Resumo por ferramenta (todos os mÃ³dulos):",
        "  â€¢ golangci-lint: ð„‚ 0 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "  â€¢ govet: ð„‚ 36 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "  â€¢ staticcheck: ð„‚ 0 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "",
        "ðŸ” Top issues prioritÃ¡rios (FAIL):",
        "  1. [govet] internal/mcp/protocol/router.go:6 - \"strings\" imported and not used (govet)",
        "  2. [govet] internal/mcp/protocol/router.go:215 - parseParams redeclared in this block (govet)",
        "  3. [govet] internal/mcp/protocol/handlers.go:779 - other declaration of parseParams (govet)",
        "  4. [govet] internal/mcp/protocol/tools.go:358 - undefined: protocol (govet)",
        "  5. [govet] internal/mcp/protocol/handlers.go:8 - \"strings\" imported and not used (govet)",
        "  6. [govet] internal/mcp/protocol/handlers.go:345 - h.parseParams undefined (type *ListTemplatesHandler has no field or me... (govet)",
        "  7. [govet] internal/mcp/protocol/handlers.go:447 - h.parseParams undefined (type *ListProjectsHandler has no field or met... (govet)",
        "  8. [govet] vet.exe: cmd/core-inventory/main.go:17 - nats redeclared in this block (govet)",
        "  9. [govet] tools/generators/mcp_generator.go:6 - \"path/filepath\" imported and not used (govet)",
        "  10. [govet] vet.exe: internal/ai/knowledge/indexer_test.go:68 - not enough arguments in call to NewIndexer (govet)"
      ],
      "non_fixable_reason": "BUSINESS_LOGIC",
      "code_contexts": null,
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 36,
        "affected_lines": 36,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "1h12m",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [
        "performance",
        "memory-optimization"
      ],
      "error_breakdown": {
        "govet": 36
      },
      "top_files": [
        "internal/security/encryption/key_manager.go (7)",
        "internal/security/encryption/encryption_manager.go (4)",
        "internal/mcp/protocol/handlers.go (4)",
        "pkg/httpserver/server_test.go (2)",
        "internal/mcp/protocol/router.go (2)"
      ]
    },
    {
      "type": "NATS subjects documentados",
      "severity": "low",
      "location": "multiplos arquivos",
      "description": "NATS subjects nao documentados",
      "suggestion": "Crie docs/NATS_SUBJECTS.md",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "tools": null,
        "executable_steps": null,
        "estimated_time": "",
        "confidence": 0
      },
      "examples": null,
      "code_contexts": null,
      "impact_analysis": {
        "severity": "",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "",
        "priority": 0,
        "risk_level": "",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    }
  ],
  "total_gaps": 5,
  "score": 75,
  "auto_fixable": 0,
  "manual": 5,
  "top_priorities": [
    {
      "type": "Nil Pointer Check",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "1 potencial(is) nil pointer issue(s)",
      "suggestion": "Adicione nil checks",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "tools": null,
        "executable_steps": null,
        "estimated_time": "",
        "confidence": 0
      },
      "examples": [
        "multi_level_cache.go:180"
      ],
      "code_contexts": null,
      "impact_analysis": {
        "severity": "",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "",
        "priority": 0,
        "risk_level": "",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "NATS subjects documentados",
      "severity": "low",
      "location": "multiplos arquivos",
      "description": "NATS subjects nao documentados",
      "suggestion": "Crie docs/NATS_SUBJECTS.md",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "tools": null,
        "executable_steps": null,
        "estimated_time": "",
        "confidence": 0
      },
      "examples": null,
      "code_contexts": null,
      "impact_analysis": {
        "severity": "",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "",
        "priority": 0,
        "risk_level": "",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "No Code Conflicts",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Conflitos de declaracao detectados",
      "suggestion": "Remova ou renomeie as declaracoes duplicadas",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": true,
        "requires_review": true,
        "manual_steps": "1. Identifique qual declaracao manter\n2. Remova ou renomeie as duplicatas\n3. Atualize referencias",
        "non_fixable_reason": "ARCHITECTURAL",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "15-30 minutos",
        "confidence": 0
      },
      "examples": [
        "cli: 'init' declarado em ai.go, generate.go, monitor.go, root.go, state.go, template.go, version.go",
        "encryption: 'Manager' declarado em certificate_manager.go, encryption_manager.go, key_manager.go",
        "protocol: 'parseParams' declarado em handlers.go, router.go",
        "analytics: 'init' declarado em metrics.go, performance.go",
        "crush: 'max' declarado em batch_processor.go, parallel_processor.go",
        "crush: 'min' declarado em batch_processor.go, parallel_processor.go"
      ],
      "non_fixable_reason": "ARCHITECTURAL",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\generate.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"MCP project generation initiated\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(generateCmd)\n    46 | \tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n    47 | \tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n    48 | \tgenerateCmd.MarkFlagRequired(\"template\")\n    49 | }\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(generateCmd)\n\tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n\tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n\tgenerateCmd.MarkFlagRequired(\"template\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\monitor.go",
          "line_number": 24,
          "code_snippet": "    19 | \t\tcmd.Println(\"System status: Operational\")\n    20 | \t\treturn nil\n    21 | \t},\n    22 | }\n    23 | \nâ†’   24 | func init() {\n    25 | \trootCmd.AddCommand(monitorCmd)\n    26 | }\n    27 | \n    28 | // SetMonitoringService sets the monitoring service\n    29 | func SetMonitoringService(service *services.MonitoringAppService) {\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(monitorCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\root.go",
          "line_number": 39,
          "code_snippet": "    34 | \t\tos.Exit(1)\n    35 | \t}\n    36 | }\n    37 | \n    38 | // init initializes the CLI\nâ†’   39 | func init() {\n    40 | \trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n    41 | \trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n    42 | \n    43 | \t// Add subcommand groups\n    44 | \trootCmd.AddCommand(analytics.AnalyticsCmd)\n",
          "full_function": "func init() {\n\trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n\trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n\n\t// Add subcommand groups\n\trootCmd.AddCommand(analytics.AnalyticsCmd)\n\trootCmd.AddCommand(ci.CICmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "os",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/analytics",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/ci",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\state.go",
          "line_number": 20,
          "code_snippet": "    15 | \t\tcmd.Println(\"State management - service implementation pending\")\n    16 | \t\treturn nil\n    17 | \t},\n    18 | }\n    19 | \nâ†’   20 | func init() {\n    21 | \trootCmd.AddCommand(stateCmd)\n    22 | }\n    23 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(stateCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\template.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"Template created\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(templateCmd)\n    46 | \ttemplateCmd.AddCommand(templateListCmd)\n    47 | \ttemplateCmd.AddCommand(templateCreateCmd)\n    48 | \ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n    49 | \ttemplateCreateCmd.MarkFlagRequired(\"name\")\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(templateCmd)\n\ttemplateCmd.AddCommand(templateListCmd)\n\ttemplateCmd.AddCommand(templateCreateCmd)\n\ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n\ttemplateCreateCmd.MarkFlagRequired(\"name\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\version.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\tfmt.Printf(\"Version: %s\\n\", Version)\n    17 | \t\tfmt.Printf(\"Build Date: %s\\n\", BuildDate)\n    18 | \t},\n    19 | }\n    20 | \nâ†’   21 | func init() {\n    22 | \trootCmd.AddCommand(versionCmd)\n    23 | }\n    24 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(versionCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "parseParams",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\analytics\\performance.go",
          "line_number": 23,
          "code_snippet": "    18 | \t\tcmd.Println(\"  P95 Latency: 0ms\")\n    19 | \t\treturn nil\n    20 | \t},\n    21 | }\n    22 | \nâ†’   23 | func init() {\n    24 | \tAnalyticsCmd.AddCommand(performanceCmd)\n    25 | }\n    26 | \n",
          "full_function": "func init() {\n\tAnalyticsCmd.AddCommand(performanceCmd)\n}",
          "symbol_name": "init",
          "package_name": "analytics",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "min",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "10-30 minutos",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "Linter limpo",
      "severity": "low",
      "location": "multiplos arquivos",
      "description": "âœ— FAIL: 36 issues crÃ­ticos, 0 warnings",
      "suggestion": "Corrija os issues FAIL primeiro, depois warnings",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": true,
        "requires_review": true,
        "non_fixable_reason": "BUSINESS_LOGIC",
        "tools": [
          {
            "tool_name": "golangci-lint",
            "install_command": "go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest",
            "diagnose_command": "golangci-lint run",
            "fix_command": "# NAO use --fix automaticamente, revise cada issue",
            "config_required": true,
            "config_template": ".golangci.yml com linters selecionados",
            "documentation": "https://golangci-lint.run/",
            "alternative_tools": null
          },
          {
            "tool_name": "staticcheck",
            "install_command": "go install honnef.co/go/tools/cmd/staticcheck@latest",
            "diagnose_command": "staticcheck ./...",
            "fix_command": "# Manual - staticcheck nao tem auto-fix",
            "config_required": false,
            "config_template": "",
            "documentation": "https://staticcheck.io/",
            "alternative_tools": null
          },
          {
            "tool_name": "gosec",
            "install_command": "go install github.com/securego/gosec/v2/cmd/gosec@latest",
            "diagnose_command": "gosec ./...",
            "fix_command": "# Manual - corrija issues de seguranca",
            "config_required": false,
            "config_template": "",
            "documentation": "https://github.com/securego/gosec",
            "alternative_tools": null
          }
        ],
        "executable_steps": null,
        "estimated_time": "1h12m",
        "confidence": 0
      },
      "examples": [
        "ðŸ“¦ MÃ³dulos analisados: 1",
        "ðŸ“„ Linter Report v3: JSON + SARIF gerados",
        "",
        "ðŸ“Š Resumo por ferramenta (todos os mÃ³dulos):",
        "  â€¢ golangci-lint: ð„‚ 0 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "  â€¢ govet: ð„‚ 36 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "  â€¢ staticcheck: ð„‚ 0 FAIL / âš  0 WARN / â„¹ 0 INFO",
        "",
        "ðŸ” Top issues prioritÃ¡rios (FAIL):",
        "  1. [govet] internal/mcp/protocol/router.go:6 - \"strings\" imported and not used (govet)",
        "  2. [govet] internal/mcp/protocol/router.go:215 - parseParams redeclared in this block (govet)",
        "  3. [govet] internal/mcp/protocol/handlers.go:779 - other declaration of parseParams (govet)",
        "  4. [govet] internal/mcp/protocol/tools.go:358 - undefined: protocol (govet)",
        "  5. [govet] internal/mcp/protocol/handlers.go:8 - \"strings\" imported and not used (govet)",
        "  6. [govet] internal/mcp/protocol/handlers.go:345 - h.parseParams undefined (type *ListTemplatesHandler has no field or me... (govet)",
        "  7. [govet] internal/mcp/protocol/handlers.go:447 - h.parseParams undefined (type *ListProjectsHandler has no field or met... (govet)",
        "  8. [govet] vet.exe: cmd/core-inventory/main.go:17 - nats redeclared in this block (govet)",
        "  9. [govet] tools/generators/mcp_generator.go:6 - \"path/filepath\" imported and not used (govet)",
        "  10. [govet] vet.exe: internal/ai/knowledge/indexer_test.go:68 - not enough arguments in call to NewIndexer (govet)"
      ],
      "non_fixable_reason": "BUSINESS_LOGIC",
      "code_contexts": null,
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 36,
        "affected_lines": 36,
        "blocks_deploy": false,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "1h12m",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [
        "performance",
        "memory-optimization"
      ],
      "error_breakdown": {
        "govet": 36
      },
      "top_files": [
        "internal/security/encryption/key_manager.go (7)",
        "internal/security/encryption/encryption_manager.go (4)",
        "internal/mcp/protocol/handlers.go (4)",
        "pkg/httpserver/server_test.go (2)",
        "internal/mcp/protocol/router.go (2)"
      ]
    },
    {
      "type": "Codigo compila",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Nao compila: # github.com/vertikon/mcp-core-inventory/internal/mcp/protocol\ninternal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used\ninternal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in thi...",
      "suggestion": "Corrija os erros de compilacao listados",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "non_fixable_reason": "BUSINESS_LOGIC",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "Variavel - depende dos erros",
        "confidence": 0
      },
      "examples": [
        "ðŸ“„ Log completo: E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\docs\\validation\\raw\\2025-11-21-21-15-18-compilation.log",
        "",
        "# github.com/vertikon/mcp-core-inventory/internal/mcp/protocol",
        "internal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in this block",
        "\tinternal\\mcp\\protocol\\handlers.go:779:6: other declaration of parseParams",
        "internal\\mcp\\protocol\\tools.go:358:64: undefined: protocol",
        "internal\\mcp\\protocol\\handlers.go:8:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\handlers.go:345:4: h.parseParams undefined (type *ListTemplatesHandler has no field or method parseParams)",
        "internal\\mcp\\protocol\\handlers.go:447:4: h.parseParams undefined (type *ListProjectsHandler has no field or method parseParams)",
        "# github.com/vertikon/mcp-core-inventory/tools/generators",
        "tools\\generators\\mcp_generator.go:6:2: \"path/filepath\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/cmd/core-inventory",
        "cmd\\core-inventory\\main.go:17:2: nats redeclared in this block",
        "\tcmd\\core-inventory\\main.go:16:2: other declaration of nats",
        "cmd\\core-inventory\\main.go:19:2: redis redeclared in this block",
        "\tcmd\\core-inventory\\main.go:14:2: other declaration of redis",
        "cmd\\core-inventory\\main.go:21:2: http redeclared in this block",
        "\tcmd\\core-inventory\\main.go:8:2: other declaration of http",
        "cmd\\core-inventory\\main.go:90:22: undefined: redis.NewStockCache",
        "cmd\\core-inventory\\main.go:91:27: undefined: redis.NewReservationLock",
        "cmd\\core-inventory\\main.go:92:19: undefined: nats.NewEventPublisher",
        "cmd\\core-inventory\\main.go:104:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewConfirmReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:111:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewReleaseReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:117:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.MovementRepository value in argument to app.NewAdjustStockUseCase: *postgres.LedgerRepository does not implement app.MovementRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.StockMovement) error",
        "cmd\\core-inventory\\main.go:143:17: undefined: http.NewRouter",
        "cmd\\core-inventory\\main.go:143:17: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/crush",
        "internal\\core\\crush\\parallel_processor.go:625:6: min redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:796:6: other declaration of min",
        "internal\\core\\crush\\parallel_processor.go:632:6: max redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:803:6: other declaration of max",
        "internal\\core\\crush\\batch_processor.go:269:19: undefined: runtime",
        "internal\\core\\crush\\batch_processor.go:427:6: declared and not used: id",
        "internal\\core\\crush\\batch_processor.go:560:18: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.AddInt64",
        "internal\\core\\crush\\batch_processor.go:584:42: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.LoadInt64",
        "internal\\core\\crush\\batch_processor.go:781:15: undefined: NewWorkerPool",
        "internal\\core\\crush\\batch_processor.go:792:23: too many arguments in call to abp.workerPool.Start",
        "\thave (context.Context)",
        "\twant ()",
        "internal\\core\\crush\\memory_optimizer.go:494:20: cannot use \u0026mo.stats.TotalMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: cannot use \u0026mo.stats.UsedMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/state",
        "internal\\core\\state\\distributed_store.go:543:22: invalid operation: cannot take address of dss.stats.LockWaitTime.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:649:31: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:651:21: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:656:31: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:658:21: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\store.go:10:2: \"github.com/vertikon/mcp-core-inventory/pkg/logger\" imported and not used",
        "internal\\core\\state\\store.go:11:2: \"go.uber.org/zap\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/core/transformer",
        "internal\\core\\transformer\\feedforward.go:194:21: ffn.router undefined (type *FeedForwardNetwork has no field or method router)",
        "internal\\core\\transformer\\transformer.go:152:38: not enough arguments in call to t.embeddings.Forward",
        "\thave (*Tensor)",
        "\twant (context.Context, *Tensor)",
        "internal\\core\\transformer\\transformer.go:209:79: cannot use attentionMask (variable of type *Tensor) as *AttentionMask value in argument to l.attention.Forward",
        "internal\\core\\transformer\\transformer.go:215:28: cannot use attnOutput (variable of type *AttentionResult) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\transformer.go:249:65: cannot use ln.eps (variable of type float64) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\positional_encoding.go:6:2: \"fmt\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/infrastructure/persistence/relational",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:198:2: declared and not used: knowledge",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:203:9: undefined: knowledgePtr",
        "# github.com/vertikon/mcp-core-inventory/internal/state/cache",
        "internal\\state\\cache\\cache_coherency.go:162:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "internal\\state\\cache\\cache_coherency.go:217:11: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:253:34: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:342:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "# github.com/vertikon/mcp-core-inventory/internal/security/encryption",
        "internal\\security\\encryption\\encryption_manager.go:56:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\encryption_manager.go:64:3: unknown field keyManager in struct literal of type Manager",
        "internal\\security\\encryption\\encryption_manager.go:71:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\encryption_manager.go:81:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\key_manager.go:52:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\key_manager.go:72:3: unknown field keyVersion in struct literal of type Manager",
        "internal\\security\\encryption\\key_manager.go:82:6: km.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:96:4: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:97:10: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:99:7: m.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:99:7: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/store",
        "internal\\state\\store\\conflict_resolver.go:236:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:238:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:251:2: declared and not used: localTime",
        "internal\\state\\store\\conflict_resolver.go:252:2: declared and not used: remoteTime",
        "internal\\state\\store\\conflict_resolver.go:283:51: too many arguments in call to r.isMergeableValue",
        "\thave (interface{}, interface{})",
        "\twant (interface{})",
        "internal\\state\\store\\conflict_resolver.go:396:9: v declared and not used",
        "internal\\state\\store\\conflict_resolver.go:415:13: r.mergeMaps undefined (type map[string]interface{} has no field or method mergeMaps)",
        "internal\\state\\store\\conflict_resolver.go:419:13: r.mergeArrays undefined (type []interface{} has no field or method mergeArrays)",
        "internal\\state\\store\\conflict_resolver.go:516:35: cannot use localTS (variable of struct type time.Time) as uint64 value in argument to max",
        "internal\\state\\store\\conflict_resolver.go:622:6: max redeclared in this block",
        "\tinternal\\state\\store\\conflict_resolver.go:615:6: other declaration of max",
        "internal\\state\\store\\conflict_resolver.go:516:35: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/events",
        "internal\\state\\events\\event_replay.go:249:2: declared and not used: snapshot",
        "internal\\state\\events\\event_replay.go:290:2: declared and not used: events",
        "internal\\state\\events\\event_versioning.go:140:4: invalid operation: cannot call copy (variable of struct type VersionInfo): VersionInfo is not a function",
        "internal\\state\\events\\event_versioning.go:216:30: ev.resolveVersionConflict undefined (type *EventVersioningImpl has no field or method resolveVersionConflict, but does have method ResolveVersionConflict)",
        ""
      ],
      "non_fixable_reason": "BUSINESS_LOGIC",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 6,
          "code_snippet": "     1 | package protocol\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"strings\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n     9 | \t\"go.uber.org/zap\"\n    10 | )\n    11 | \n",
          "full_function": "\t\"strings\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// ToolRouter handles routing of MCP tool requests to appropriate handlers\ntype ToolRouter struct {\n\thandlers map[string]ToolHandler\n\tlogger   *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\mcp\\protocol\\handlers.go",
          "line_number": 779,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\tools.go",
          "line_number": 358,
          "code_snippet": "   353 | func (h *ToolHandlerImpl) Schema() map[string]interface{} {\n   354 | \treturn h.schema\n   355 | }\n   356 | \n   357 | // Handle processes the tool request\nâ†’  358 | func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n   359 | \th.logger.Info(\"Handling tool request\",\n   360 | \t\tzap.String(\"tool\", h.name),\n   361 | \t\tzap.Any(\"params\", request.Params))\n   362 | \n   363 | \t// This is a placeholder implementation\n",
          "full_function": "func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n\th.logger.Info(\"Handling tool request\",\n\t\tzap.String(\"tool\", h.name),\n\t\tzap.Any(\"params\", request.Params))\n\n\t// This is a placeholder implementation\n\t// In a real implementation, each tool would have its own handler logic\n\tresult := map[string]interface{}{\n\t\t\"tool\":    h.name,\n\t\t\"status\":  \"implemented\",\n\t\t\"message\": fmt.Sprintf(\"Tool %s is ready for implementation\", h.name),\n\t}\n\n\treturn NewSuccessResponse(request.ID, result), nil\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 8,
          "code_snippet": "     3 | import (\n     4 | \t\"context\"\n     5 | \t\"encoding/json\"\n     6 | \t\"fmt\"\n     7 | \t\"os\"\nâ†’    8 | \t\"strings\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n    12 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n    13 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n",
          "full_function": "\t\"strings\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// HandlerManager manages all MCP tool handlers\ntype HandlerManager struct {\n\tgeneratorFactory *generators.GeneratorFactory\n\tvalidatorFactory *validators.ValidatorFactory\n\tregistry         *registry.MCPRegistry\n\tlogger           *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 345,
          "code_snippet": "   340 | \tvar params struct {\n   341 | \t\tStack    string `json:\"stack,omitempty\"`\n   342 | \t\tCategory string `json:\"category,omitempty\"`\n   343 | \t}\n   344 | \nâ†’  345 | \th.parseParams(request.Params, \u0026params)\n   346 | \n   347 | \ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n   348 | \t\tStack:    params.Stack,\n   349 | \t\tCategory: params.Category,\n   350 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n\t\tStack:    params.Stack,\n\t\tCategory: params.Category,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 447,
          "code_snippet": "   442 | \tvar params struct {\n   443 | \t\tStack  string `json:\"stack,omitempty\"`\n   444 | \t\tStatus string `json:\"status,omitempty\"`\n   445 | \t}\n   446 | \nâ†’  447 | \th.parseParams(request.Params, \u0026params)\n   448 | \n   449 | \tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n   450 | \t\tStack:  params.Stack,\n   451 | \t\tStatus: params.Status,\n   452 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n\t\tStack:  params.Stack,\n\t\tStatus: params.Status,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\tools\\generators\\mcp_generator.go",
          "line_number": 6,
          "code_snippet": "     1 | package generators\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"path/filepath\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n     9 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    10 | \t\"go.uber.org/zap\"\n    11 | )\n",
          "full_function": "\t\"path/filepath\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// MCPGenerator orchestrates MCP generation using internal/mcp/generators\n// This is the CLI/Tool interface for generating MCPs\ntype MCPGenerator struct {\n\tfactory *generators.GeneratorFactory\n\tlogger  *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "generators",
          "dependencies": [
            "context",
            "fmt",
            "path/filepath",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 17,
          "code_snippet": "    12 | \t\"time\"\n    13 | \n    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\nâ†’   17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 16,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 19,
          "code_snippet": "    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\nâ†’   19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 14,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\nâ†’   21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    25 | \t\"go.uber.org/zap\"\n    26 | )\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 8,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 90,
          "code_snippet": "    85 | \t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\nâ†’   90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 91,
          "code_snippet": "    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\nâ†’   91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 92,
          "code_snippet": "    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\nâ†’   92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n    97 | \t\treservationLock,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 104,
          "code_snippet": "    99 | \t\tlogger.GetLogger(),\n   100 | \t)\n   101 | \n   102 | \tconfirmUseCase := app.NewConfirmReservationUseCase(\n   103 | \t\tledgerRepo,\nâ†’  104 | \t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n   105 | \t\teventPub,\n   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 111,
          "code_snippet": "   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n   110 | \t\tledgerRepo,\nâ†’  111 | \t\tledgerRepo,\n   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 117,
          "code_snippet": "   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\nâ†’  117 | \t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n   118 | \t\tlogger.GetLogger(),\n   119 | \t)\n   120 | \n   121 | \tqueryUseCase := app.NewQueryAvailableUseCase(\n   122 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 796,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 803,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 269,
          "code_snippet": "   264 | \n   265 | \t// Initialize async processor\n   266 | \tif config.EnableAsync {\n   267 | \t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n   268 | \t\t\tEnabled:       true,\nâ†’  269 | \t\t\tNumWorkers:    runtime.NumCPU(),\n   270 | \t\t\tQueueSize:     100,\n   271 | \t\t\tWorkerTimeout: config.Timeout,\n   272 | \t\t\tRetryAttempts: 3,\n   273 | \t\t})\n   274 | \t}\n",
          "full_function": "func NewBatchProcessor(config BatchProcessorConfig) *BatchProcessor {\n\tif config.MaxBatchSize == 0 {\n\t\tconfig.MaxBatchSize = 32\n\t}\n\tif config.MinBatchSize == 0 {\n\t\tconfig.MinBatchSize = 1\n\t}\n\tif config.Timeout == 0 {\n\t\tconfig.Timeout = 5 * time.Second\n\t}\n\n\tlogger.Info(\"Creating batch processor\",\n\t\tzap.Int(\"max_batch_size\", config.MaxBatchSize),\n\t\tzap.Int(\"min_batch_size\", config.MinBatchSize),\n\t\tzap.Duration(\"timeout\", config.Timeout),\n\t\tzap.Bool(\"dynamic_batching\", config.EnableDynamicBatching),\n\t\tzap.Bool(\"prefetch\", config.EnablePrefetch),\n\t\tzap.Bool(\"async\", config.EnableAsync),\n\t)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\n\tprocessor := \u0026BatchProcessor{\n\t\tconfig:      config,\n\t\tbatches:     make(map[string]*Batch),\n\t\tbatchQueue:  make(chan *Batch, 100),\n\t\tresultQueue: make(chan *BatchResult, 100),\n\t\tctx:         ctx,\n\t\tcancel:      cancel,\n\t\tstats:       \u0026BatchProcessorStats{},\n\t}\n\n\t// Initialize dynamic sizing\n\tif config.EnableDynamicBatching {\n\t\tprocessor.dynamicSizing = NewDynamicBatchSizer(DynamicSizingConfig{\n\t\t\tEnabled:       true,\n\t\t\tStrategy:      StrategyAdaptive,\n\t\t\tMinSize:       config.MinBatchSize,\n\t\t\tMaxSize:       config.MaxBatchSize,\n\t\t\tTargetLatency: config.MaxLatency,\n\t\t})\n\t}\n\n\t// Initialize prefetcher\n\tif config.EnablePrefetch {\n\t\tprocessor.prefetcher = NewBatchPrefetcher(PrefetchConfig{\n\t\t\tEnabled:        true,\n\t\t\tPrefetchSize:   config.MaxBatchSize,\n\t\t\tCacheSize:      100,\n\t\t\tPrefetchPolicy: PolicyPredictive,\n\t\t})\n\t}\n\n\t// Initialize async processor\n\tif config.EnableAsync {\n\t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n\t\t\tEnabled:       true,\n\t\t\tNumWorkers:    runtime.NumCPU(),\n\t\t\tQueueSize:     100,\n\t\t\tWorkerTimeout: config.Timeout,\n\t\t\tRetryAttempts: 3,\n\t\t})\n\t}\n\n\treturn processor\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 427,
          "code_snippet": "   422 | func (bp *BatchProcessor) checkBatchTimeouts() {\n   423 | \tbp.mu.Lock()\n   424 | \tdefer bp.mu.Unlock()\n   425 | \n   426 | \tnow := time.Now()\nâ†’  427 | \tfor id, batch := range bp.batches {\n   428 | \t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n   429 | \t\t\tbp.submitBatch(batch)\n   430 | \t\t}\n   431 | \t}\n   432 | }\n",
          "full_function": "func (bp *BatchProcessor) checkBatchTimeouts() {\n\tbp.mu.Lock()\n\tdefer bp.mu.Unlock()\n\n\tnow := time.Now()\n\tfor id, batch := range bp.batches {\n\t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n\t\t\tbp.submitBatch(batch)\n\t\t}\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 560,
          "code_snippet": "   555 | // updateStats updates batch processing statistics\n   556 | func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n   557 | \tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n   558 | \tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n   559 | \tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\nâ†’  560 | \tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n   561 | \n   562 | \tif len(result.Errors) \u003e 0 {\n   563 | \t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n   564 | \t}\n   565 | }\n",
          "full_function": "func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n\tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n\tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n\n\tif len(result.Errors) \u003e 0 {\n\t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 584,
          "code_snippet": "   579 | \t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n   580 | \t}\n   581 | \n   582 | \t// Calculate average processing time\n   583 | \tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\nâ†’  584 | \ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n   585 | \n   586 | \tif completedBatches \u003e 0 {\n   587 | \t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n   588 | \t}\n   589 | \n",
          "full_function": "func (bp *BatchProcessor) collectStats() {\n\tbp.stats.LastUpdated = time.Now()\n\n\t// Calculate queue utilization\n\tbp.stats.QueueUtilization = float64(len(bp.batchQueue)) / float64(cap(bp.batchQueue))\n\n\t// Calculate average batch size\n\ttotalBatches := atomic.LoadInt64(\u0026bp.stats.TotalBatches)\n\ttotalItems := atomic.LoadInt64(\u0026bp.stats.TotalItems)\n\n\tif totalBatches \u003e 0 {\n\t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n\t}\n\n\t// Calculate average processing time\n\tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\n\ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n\t}\n\n\t// Calculate throughput\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.Throughput = float64(totalItems) / time.Since(time.Now()).Seconds()\n\t}\n\n\tlogger.Debug(\"Batch processor stats\",\n\t\tzap.Float64(\"queue_utilization\", bp.stats.QueueUtilization),\n\t\tzap.Float64(\"avg_batch_size\", bp.stats.AvgBatchSize),\n\t\tzap.Duration(\"avg_processing_time\", bp.stats.AvgProcessingTime),\n\t\tzap.Float64(\"throughput\", bp.stats.Throughput),\n\t)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 781,
          "code_snippet": "   776 | \n   777 | // NewAsyncBatchProcessor creates a new async batch processor\n   778 | func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n   779 | \treturn \u0026AsyncBatchProcessor{\n   780 | \t\tconfig:     config,\nâ†’  781 | \t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n   782 | \t\tstats:      \u0026AsyncProcessingStats{},\n   783 | \t}\n   784 | }\n   785 | \n   786 | // Start starts async batch processor\n",
          "full_function": "func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n\treturn \u0026AsyncBatchProcessor{\n\t\tconfig:     config,\n\t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n\t\tstats:      \u0026AsyncProcessingStats{},\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 792,
          "code_snippet": "   787 | func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n   788 | \tif !abp.config.Enabled {\n   789 | \t\treturn\n   790 | \t}\n   791 | \nâ†’  792 | \tabp.workerPool.Start(ctx)\n   793 | }\n   794 | \n   795 | // Additional helper functions\n   796 | func min(a, b int) int {\n   797 | \tif a \u003c b {\n",
          "full_function": "func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n\tif !abp.config.Enabled {\n\t\treturn\n\t}\n\n\tabp.workerPool.Start(ctx)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 494,
          "code_snippet": "   489 | \t\ttotalMemory += segment.Size\n   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \nâ†’  494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n   495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 543,
          "code_snippet": "   538 | \t}\n   539 | \n   540 | \tstart := time.Now()\n   541 | \tdefer func() {\n   542 | \t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\nâ†’  543 | \t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n   544 | \t}()\n   545 | \n   546 | \t// Try remote store first\n   547 | \tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n   548 | \tif err == nil {\n",
          "full_function": "func (dss *DistributedStateStore) Lock(ctx context.Context, key string, ttl time.Duration) (*Lock, error) {\n\tif !dss.config.EnableLocking {\n\t\treturn nil, fmt.Errorf(\"locking is not enabled\")\n\t}\n\n\tstart := time.Now()\n\tdefer func() {\n\t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\n\t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n\t}()\n\n\t// Try remote store first\n\tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n\tif err == nil {\n\t\treturn lock, nil\n\t}\n\n\t// Fallback to local store\n\treturn dss.localStore.Lock(ctx, key, ttl)\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 649,
          "code_snippet": "   644 | \treturn *dss.stats\n   645 | }\n   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\nâ†’  649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 651,
          "code_snippet": "   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n   649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 656,
          "code_snippet": "   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\nâ†’  656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 658,
          "code_snippet": "   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n   662 | func NewMemoryStateStore() *MemoryStateStore {\n   663 | \treturn \u0026MemoryStateStore{\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 10,
          "code_snippet": "     5 | \t\"context\"\n     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\nâ†’   10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 11,
          "code_snippet": "     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\n    10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\nâ†’   11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n    16 | \tdb *badger.DB\n",
          "full_function": "\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\feedforward.go",
          "line_number": 194,
          "code_snippet": "   189 | }\n   190 | \n   191 | // forwardMoE performs mixture of experts computation\n   192 | func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n   193 | \t// Router determines which experts to use\nâ†’  194 | \trouter, err := ffn.router.Forward(input)\n   195 | \tif err != nil {\n   196 | \t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n   197 | \t}\n   198 | \n   199 | \t// Select top-k experts\n",
          "full_function": "func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n\t// Router determines which experts to use\n\trouter, err := ffn.router.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n\t}\n\n\t// Select top-k experts\n\tselectedExperts := ffn.selectTopKExperts(router)\n\n\t// Combine expert outputs\n\toutput := ffn.combineExperts(input, selectedExperts)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 152,
          "code_snippet": "   147 | \t\treturn nil, ctx.Err()\n   148 | \tdefault:\n   149 | \t}\n   150 | \n   151 | \t// Embedding layer\nâ†’  152 | \thidden, err := t.embeddings.Forward(input)\n   153 | \tif err != nil {\n   154 | \t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n   155 | \t}\n   156 | \n   157 | \t// Add positional encoding\n",
          "full_function": "func (t *GLMTransformer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tt.mu.RLock()\n\tdefer t.mu.RUnlock()\n\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Embedding layer\n\thidden, err := t.embeddings.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n\t}\n\n\t// Add positional encoding\n\tif t.posEncoding != nil {\n\t\tposEncoded, err := t.posEncoding.Forward(ctx, hidden, 0)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"positional encoding error: %w\", err)\n\t\t}\n\t\thidden = posEncoded\n\t}\n\n\t// Pass through transformer layers\n\tfor i, layer := range t.layers {\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tlayerOutput, err := layer.Forward(ctx, hidden, attentionMask)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"layer %d error: %w\", i, err)\n\t\t}\n\t\thidden = layerOutput\n\n\t\tlogger.Debug(\"Transformer layer processed\",\n\t\t\tzap.Int(\"layer\", i),\n\t\t\tzap.Float64(\"mean_activation\", t.meanActivation(hidden)),\n\t\t)\n\t}\n\n\t// Final layer norm\n\toutput, err := t.layernorm.Forward(hidden)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"final layer norm error: %w\", err)\n\t}\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 209,
          "code_snippet": "   204 | \tnormInput, err := l.layernorm1.Forward(input)\n   205 | \tif err != nil {\n   206 | \t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n   207 | \t}\n   208 | \nâ†’  209 | \tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 215,
          "code_snippet": "   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\nâ†’  215 | \tresidual1 := t.add(input, attnOutput)\n   216 | \n   217 | \t// Pre-norm + feed-forward\n   218 | \tnormResidual, err := l.layernorm2.Forward(residual1)\n   219 | \tif err != nil {\n   220 | \t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 249,
          "code_snippet": "   244 | // Forward performs layer normalization\n   245 | func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n   246 | \t// Simplified layer norm implementation\n   247 | \tmean := t.mean(input, -1, true)\n   248 | \tvariance := t.variance(input, -1, true)\nâ†’  249 | \tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n   250 | \n   251 | \t// Scale and shift\n   252 | \toutput := t.mul(normalized, ln.weight)\n   253 | \toutput = t.add(output, ln.bias)\n   254 | \n",
          "full_function": "func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n\t// Simplified layer norm implementation\n\tmean := t.mean(input, -1, true)\n\tvariance := t.variance(input, -1, true)\n\tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n\n\t// Scale and shift\n\toutput := t.mul(normalized, ln.weight)\n\toutput = t.add(output, ln.bias)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\positional_encoding.go",
          "line_number": 6,
          "code_snippet": "     1 | // Package transformer implements positional encoding for GLM-4.6\n     2 | package transformer\n     3 | \n     4 | import (\n     5 | \t\"context\"\nâ†’    6 | \t\"fmt\"\n     7 | \t\"math\"\n     8 | \t\"sync\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"fmt\"\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// PositionalEncodingType represents different positional encoding approaches\ntype PositionalEncodingType string\n\nconst (\n\tPosEncodingTypeSinusoidal PositionalEncodingType = \"sinusoidal\"\n\tPosEncodingTypeLearned    PositionalEncodingType = \"learned\"\n\tPosEncodingTypeRelative   PositionalEncodingType = \"relative\"\n\tPosEncodingTypeRotary     PositionalEncodingType = \"rotary\"\n\tPosEncodingTypeALiBi      PositionalEncodingType = \"alibi\"\n\tPosEncodingTypeXPos       PositionalEncodingType = \"xpos\"\n)\n\n// PositionalEncodingConfig represents positional encoding configuration\ntype PositionalEncodingConfig struct {\n\tType        PositionalEncodingType `json:\"type\"`\n\tMaxSeqLen   int                    `json:\"max_seq_len\"`\n\tHiddenSize  int                    `json:\"hidden_size\"`\n\tHeadDim     int                    `json:\"head_dim,omitempty\"`\n\tBase        float64                `json:\"base\"`\n\tScale       bool                   `json:\"scale\"`\n\tNormalize   bool                   `json:\"normalize\"`\n\tConcatenate bool                   `json:\"concatenate\"`\n\tRotateHalf  bool                   `json:\"rotate_half\"`\n\tUseRoPE     bool                   `json:\"use_rope\"`\n\tUseXPos     bool                   `json:\"use_xpos\"`\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 198,
          "code_snippet": "   193 | \t}\n   194 | \tif err != nil {\n   195 | \t\treturn nil, fmt.Errorf(\"failed to find Knowledge: %w\", err)\n   196 | \t}\n   197 | \nâ†’  198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \n   203 | \treturn knowledgePtr, nil\n",
          "full_function": "\tknowledge, err := entities.NewKnowledge(name, description)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n\t}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 203,
          "code_snippet": "   198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \nâ†’  203 | \treturn knowledgePtr, nil\n   204 | }\n   205 | \n   206 | // List lists all Knowledge entities with optional filters\n   207 | func (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n   208 | \tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n",
          "full_function": "\treturn knowledgePtr, nil\n}\n\n// List lists all Knowledge entities with optional filters\nfunc (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n\tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n\targs := []interface{}{}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 162,
          "code_snippet": "   157 | \tcm.stats.TotalInvalidations++\n   158 | \tcm.stats.InvalidationsByReason[reason]++\n   159 | \tcm.mu.Unlock()\n   160 | \n   161 | \t// Delete from cache\nâ†’  162 | \tcm.cache.Delete(key)\n   163 | \n   164 | \t// Create invalidation event\n   165 | \tevent := \u0026InvalidationEvent{\n   166 | \t\tKey:       key,\n   167 | \t\tReason:    reason,\n",
          "full_function": "func (cm *CoherencyManagerImpl) Invalidate(ctx context.Context, key string, reason string) error {\n\tstart := time.Now()\n\n\tcm.mu.Lock()\n\tcm.stats.TotalInvalidations++\n\tcm.stats.InvalidationsByReason[reason]++\n\tcm.mu.Unlock()\n\n\t// Delete from cache\n\tcm.cache.Delete(key)\n\n\t// Create invalidation event\n\tevent := \u0026InvalidationEvent{\n\t\tKey:       key,\n\t\tReason:    reason,\n\t\tTimestamp: time.Now(),\n\t\tSource:    \"coherency_manager\",\n\t}\n\n\t// Send to invalidation channel\n\tselect {\n\tcase cm.invalidationCh \u003c- event:\n\tdefault:\n\t\tcm.logger.Warn(\"Invalidation channel full, dropping event\",\n\t\t\tzap.String(\"key\", key))\n\t}\n\n\tcm.mu.Lock()\n\tcm.stats.AverageInvalidationTime = time.Since(start)\n\tlastTime := time.Now()\n\tcm.stats.LastInvalidation = \u0026lastTime\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Cache key invalidated\",\n\t\tzap.String(\"key\", key),\n\t\tzap.String(\"reason\", reason))\n\n\treturn nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 217,
          "code_snippet": "   212 | }\n   213 | \n   214 | // Update updates a cache entry\n   215 | func (cm *CoherencyManagerImpl) Update(ctx context.Context, key string, value interface{}) error {\n   216 | \tcm.mu.Lock()\nâ†’  217 | \tcm.stats.TotalUpdates++\n   218 | \tcm.mu.Unlock()\n   219 | \n   220 | \t// Update cache based on strategy\n   221 | \tswitch cm.config.Strategy {\n   222 | \tcase CoherencyStrategyWriteThrough:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 253,
          "code_snippet": "   248 | \t\tStrategy:             cm.config.Strategy,\n   249 | \t\tLevel:                cm.config.Level,\n   250 | \t\tIsCoherent:           true, // Simplified\n   251 | \t\tPendingInvalidations: len(cm.pendingInvalidations),\n   252 | \t\tTotalInvalidations:   cm.stats.TotalInvalidations,\nâ†’  253 | \t\tTotalUpdates:         cm.stats.TotalUpdates,\n   254 | \t}, nil\n   255 | }\n   256 | \n   257 | // GetInvalidationStats returns invalidation statistics\n   258 | func (cm *CoherencyManagerImpl) GetInvalidationStats(ctx context.Context) (*InvalidationStats, error) {\n",
          "full_function": "func (cm *CoherencyManagerImpl) GetCoherencyStatus(ctx context.Context) (*CoherencyStatus, error) {\n\tcm.mu.RLock()\n\tdefer cm.mu.RUnlock()\n\n\treturn \u0026CoherencyStatus{\n\t\tStrategy:             cm.config.Strategy,\n\t\tLevel:                cm.config.Level,\n\t\tIsCoherent:           true, // Simplified\n\t\tPendingInvalidations: len(cm.pendingInvalidations),\n\t\tTotalInvalidations:   cm.stats.TotalInvalidations,\n\t\tTotalUpdates:         cm.stats.TotalUpdates,\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 342,
          "code_snippet": "   337 | \tcm.mu.Lock()\n   338 | \tcm.pendingInvalidations[event.Key] = event\n   339 | \tcm.mu.Unlock()\n   340 | \n   341 | \t// Process invalidation\nâ†’  342 | \tcm.cache.Delete(event.Key)\n   343 | \n   344 | \tcm.mu.Lock()\n   345 | \tdelete(cm.pendingInvalidations, event.Key)\n   346 | \tcm.mu.Unlock()\n   347 | \n",
          "full_function": "func (cm *CoherencyManagerImpl) processInvalidation(event *InvalidationEvent) {\n\tcm.mu.Lock()\n\tcm.pendingInvalidations[event.Key] = event\n\tcm.mu.Unlock()\n\n\t// Process invalidation\n\tcm.cache.Delete(event.Key)\n\n\tcm.mu.Lock()\n\tdelete(cm.pendingInvalidations, event.Key)\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Invalidation processed\",\n\t\tzap.String(\"key\", event.Key),\n\t\tzap.String(\"reason\", event.Reason))\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 64,
          "code_snippet": "    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n    62 | func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n    63 | \treturn \u0026Manager{\nâ†’   64 | \t\tkeyManager: keyManager,\n    65 | \t\tlogger:     logger.WithContext(nil),\n    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n",
          "full_function": "func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n\treturn \u0026Manager{\n\t\tkeyManager: keyManager,\n\t\tlogger:     logger.WithContext(nil),\n\t}\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 71,
          "code_snippet": "    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n    70 | func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\nâ†’   71 | \tkey, err := m.keyManager.GetEncryptionKey()\n    72 | \tif err != nil {\n    73 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    74 | \t\treturn nil, err\n    75 | \t}\n    76 | \treturn m.EncryptWithKey(plaintext, key)\n",
          "full_function": "func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.EncryptWithKey(plaintext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 81,
          "code_snippet": "    76 | \treturn m.EncryptWithKey(plaintext, key)\n    77 | }\n    78 | \n    79 | // Decrypt decrypts data using AES-256-GCM with default key\n    80 | func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\nâ†’   81 | \tkey, err := m.keyManager.GetEncryptionKey()\n    82 | \tif err != nil {\n    83 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    84 | \t\treturn nil, err\n    85 | \t}\n    86 | \treturn m.DecryptWithKey(ciphertext, key)\n",
          "full_function": "func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.DecryptWithKey(ciphertext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 72,
          "code_snippet": "    67 | }\n    68 | \n    69 | // NewKeyManager creates a new KeyManager\n    70 | func NewKeyManager(config KeyManagerConfig) KeyManager {\n    71 | \tkm := \u0026Manager{\nâ†’   72 | \t\tkeyVersion:  \"v1\",\n    73 | \t\trotationTTL: config.RotationTTL,\n    74 | \t\tlogger:      logger.WithContext(nil),\n    75 | \t}\n    76 | \n    77 | \t// Generate initial encryption key\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 82,
          "code_snippet": "    77 | \t// Generate initial encryption key\n    78 | \tkey := make([]byte, 32) // AES-256\n    79 | \tif _, err := rand.Read(key); err != nil {\n    80 | \t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n    81 | \t} else {\nâ†’   82 | \t\tkm.encryptionKey = key\n    83 | \t}\n    84 | \n    85 | \t// Generate RSA key pair\n    86 | \tif err := km.generateRSAKeys(config.KeySize); err != nil {\n    87 | \t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 96,
          "code_snippet": "    91 | \treturn km\n    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\nâ†’   96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 97,
          "code_snippet": "    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\nâ†’   97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 236,
          "code_snippet": "   231 | \t// Compare vector clocks\n   232 | \tcomparison := r.compareVectorClocks(localVC, remoteVC)\n   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\nâ†’  236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\n   238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 238,
          "code_snippet": "   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\n   236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\nâ†’  238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n   242 | \tdefault:\n   243 | \t\t// Same vector clock, use timestamp as tie-breaker\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 251,
          "code_snippet": "   246 | }\n   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\nâ†’  251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\n   252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 252,
          "code_snippet": "   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\n   251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\nâ†’  252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n   257 | \n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 283,
          "code_snippet": "   278 | func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n   279 | \t// For simple values, use last-write-wins\n   280 | \t// For complex values (maps, sets, counters), perform actual CRDT merge\n   281 | \n   282 | \t// Check if values are mergeable\nâ†’  283 | \tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n   284 | \t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n   285 | \t\tif err != nil {\n   286 | \t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n   287 | \t\t\t\tzap.String(\"key\", conflict.Key),\n   288 | \t\t\t\tzap.Error(err))\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n\t// For simple values, use last-write-wins\n\t// For complex values (maps, sets, counters), perform actual CRDT merge\n\n\t// Check if values are mergeable\n\tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n\t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n\t\tif err != nil {\n\t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n\t\t\t\tzap.String(\"key\", conflict.Key),\n\t\t\t\tzap.Error(err))\n\t\t\treturn r.resolveCRDTLastWriterWins(conflict)\n\t\t}\n\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   mergedValue,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     r.mergeTTL(conflict.LocalState.TTL, conflict.RemoteState.TTL),\n\t\t\tMeta:    r.createCRDTMergeMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta),\n\t\t}, nil\n\t}\n\n\t// Non-mergeable, fall back to LWW\n\treturn r.resolveCRDTLastWriterWins(conflict)\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 396,
          "code_snippet": "   391 | \treturn ts\n   392 | }\n   393 | \n   394 | func (r *ConflictResolverImpl) isMergeableValue(value interface{}) bool {\n   395 | \t// Check if value is a type that can be merged\nâ†’  396 | \tswitch v := value.(type) {\n   397 | \tcase map[string]interface{}:\n   398 | \t\treturn true\n   399 | \tcase []interface{}:\n   400 | \t\treturn true\n   401 | \tcase map[string]string:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 415,
          "code_snippet": "   410 | func (r *ConflictResolverImpl) mergeValues(local, remote interface{}) (interface{}, error) {\n   411 | \t// Implement actual CRDT merge logic based on value type\n   412 | \tswitch l := local.(type) {\n   413 | \tcase map[string]interface{}:\n   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\nâ†’  415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\n   419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 419,
          "code_snippet": "   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\n   415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\nâ†’  419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n   421 | \t}\n   422 | \n   423 | \t// Cannot merge, return error\n   424 | \treturn nil, fmt.Errorf(\"values are not mergeable\")\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\state\\store\\conflict_resolver.go",
          "line_number": 615,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 249,
          "code_snippet": "   244 | }\n   245 | \n   246 | // ReplayFromSnapshot replays events from a snapshot version\n   247 | func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n   248 | \t// Get snapshot\nâ†’  249 | \tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n   250 | \tif err != nil {\n   251 | \t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n   252 | \t}\n   253 | \n   254 | \t// Get events after snapshot version\n",
          "full_function": "func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n\t// Get snapshot\n\tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n\t}\n\n\t// Get events after snapshot version\n\tevents, err := er.store.GetEvents(ctx, aggregateID, snapshotVersion+1, 0)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get events after snapshot: %w\", err)\n\t}\n\n\tif len(events) == 0 {\n\t\treturn \u0026ReplayProgress{\n\t\t\tTotalEvents:     0,\n\t\t\tProcessedEvents: 0,\n\t\t\tIsComplete:      true,\n\t\t}, nil\n\t}\n\n\tstartTime := time.Now()\n\tprogress := \u0026ReplayProgress{\n\t\tTotalEvents:    int64(len(events)),\n\t\tStartTime:      startTime,\n\t\tCurrentVersion: snapshotVersion + 1,\n\t}\n\n\terr = er.replaySequential(ctx, events, handler, progress)\n\tprogress.ElapsedTime = time.Since(startTime)\n\tprogress.IsComplete = true\n\n\tif err != nil {\n\t\tprogress.LastError = err.Error()\n\t\treturn progress, err\n\t}\n\n\treturn progress, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 290,
          "code_snippet": "   285 | }\n   286 | \n   287 | // ReplayToState replays events to rebuild state at a specific version\n   288 | func (er *EventReplayImpl) ReplayToState(ctx context.Context, aggregateID string, targetVersion int64, handler ReplayHandler) (interface{}, error) {\n   289 | \t// Get all events up to target version\nâ†’  290 | \tevents, err := er.store.GetEvents(ctx, aggregateID, 1, targetVersion)\n   291 | \tif err != nil {\n   292 | \t\treturn nil, fmt.Errorf(\"failed to get events: %w\", err)\n   293 | \t}\n   294 | \n   295 | \t// Replay events\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 140,
          "code_snippet": "   135 | \tif exists {\n   136 | \t\t// Return copy\n   137 | \t\tcopy := *versionInfo\n   138 | \t\tif versionInfo.VersionHistory != nil {\n   139 | \t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\nâ†’  140 | \t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n   141 | \t\t}\n   142 | \t\treturn \u0026copy, nil\n   143 | \t}\n   144 | \n   145 | \t// Load from event store\n",
          "full_function": "func (ev *EventVersioningImpl) GetVersion(ctx context.Context, aggregateID string) (*VersionInfo, error) {\n\tev.mu.RLock()\n\tversionInfo, exists := ev.versions[aggregateID]\n\tev.mu.RUnlock()\n\n\tif exists {\n\t\t// Return copy\n\t\tcopy := *versionInfo\n\t\tif versionInfo.VersionHistory != nil {\n\t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\n\t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n\t\t}\n\t\treturn \u0026copy, nil\n\t}\n\n\t// Load from event store\n\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t}\n\n\tversionInfo = \u0026VersionInfo{\n\t\tAggregateID:    aggregateID,\n\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\tCurrentVersion: aggregateInfo.Version,\n\t\tMetadata:       make(map[string]interface{}),\n\t}\n\n\tif ev.config.EnableHistory {\n\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t}\n\n\tev.mu.Lock()\n\tev.versions[aggregateID] = versionInfo\n\tev.mu.Unlock()\n\n\treturn versionInfo, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 216,
          "code_snippet": "   211 | \t\tif ev.config.ConflictResolution == \"reject\" {\n   212 | \t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n   213 | \t\t}\n   214 | \n   215 | \t\t// Resolve conflict\nâ†’  216 | \t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n   217 | \t\tif err != nil {\n   218 | \t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n   219 | \t\t}\n   220 | \n   221 | \t\tnewVersion = resolvedVersion\n",
          "full_function": "func (ev *EventVersioningImpl) IncrementVersion(ctx context.Context, aggregateID string, event *Event) (int64, error) {\n\tev.mu.Lock()\n\tdefer ev.mu.Unlock()\n\n\tversionInfo, exists := ev.versions[aggregateID]\n\tif !exists {\n\t\t// Load from store\n\t\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t\t}\n\n\t\tversionInfo = \u0026VersionInfo{\n\t\t\tAggregateID:    aggregateID,\n\t\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\t\tCurrentVersion: aggregateInfo.Version,\n\t\t\tMetadata:       make(map[string]interface{}),\n\t\t}\n\n\t\tif ev.config.EnableHistory {\n\t\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t\t}\n\n\t\tev.versions[aggregateID] = versionInfo\n\t}\n\n\t// Increment version\n\tnewVersion := versionInfo.CurrentVersion + 1\n\n\t// Validate version continuity\n\tif event.Version != 0 \u0026\u0026 event.Version != newVersion {\n\t\tconflict := \u0026VersionConflict{\n\t\t\tAggregateID:     aggregateID,\n\t\t\tExpectedVersion: newVersion,\n\t\t\tActualVersion:   event.Version,\n\t\t\tConflictTime:    time.Now(),\n\t\t}\n\n\t\tev.stats.TotalConflicts++\n\t\tev.conflicts[aggregateID] = append(ev.conflicts[aggregateID], conflict)\n\n\t\tif ev.config.ConflictResolution == \"reject\" {\n\t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n\t\t}\n\n\t\t// Resolve conflict\n\t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n\t\t}\n\n\t\tnewVersion = resolvedVersion\n\t\tconflict.Resolution = fmt.Sprintf(\"resolved to %d\", resolvedVersion)\n\t\tev.stats.ResolvedConflicts++\n\t}\n\n\t// Update version info\n\tversionInfo.CurrentVersion = newVersion\n\tversionInfo.LastEventID = event.ID\n\tversionInfo.LastEventTime = event.Timestamp\n\n\t// Add to history\n\tif ev.config.EnableHistory {\n\t\tentry := VersionHistoryEntry{\n\t\t\tVersion:   newVersion,\n\t\t\tEventID:   event.ID,\n\t\t\tTimestamp: event.Timestamp,\n\t\t\tEventType: event.Type,\n\t\t}\n\n\t\tversionInfo.VersionHistory = append(versionInfo.VersionHistory, entry)\n\n\t\t// Trim history if needed\n\t\tif len(versionInfo.VersionHistory) \u003e ev.config.HistoryRetention {\n\t\t\tversionInfo.VersionHistory = versionInfo.VersionHistory[len(versionInfo.VersionHistory)-ev.config.HistoryRetention:]\n\t\t}\n\t}\n\n\t// Update statistics\n\tev.stats.TotalVersions++\n\tev.stats.VersionDistribution[newVersion]++\n\n\tev.logger.Debug(\"Version incremented\",\n\t\tzap.String(\"aggregate_id\", aggregateID),\n\t\tzap.Int64(\"version\", newVersion))\n\n\treturn newVersion, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 25,
        "affected_lines": 83,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "1-2 horas",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    }
  ],
  "quick_wins": null,
  "blockers": [
    {
      "type": "No Code Conflicts",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Conflitos de declaracao detectados",
      "suggestion": "Remova ou renomeie as declaracoes duplicadas",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": true,
        "requires_review": true,
        "manual_steps": "1. Identifique qual declaracao manter\n2. Remova ou renomeie as duplicatas\n3. Atualize referencias",
        "non_fixable_reason": "ARCHITECTURAL",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "15-30 minutos",
        "confidence": 0
      },
      "examples": [
        "cli: 'init' declarado em ai.go, generate.go, monitor.go, root.go, state.go, template.go, version.go",
        "encryption: 'Manager' declarado em certificate_manager.go, encryption_manager.go, key_manager.go",
        "protocol: 'parseParams' declarado em handlers.go, router.go",
        "analytics: 'init' declarado em metrics.go, performance.go",
        "crush: 'max' declarado em batch_processor.go, parallel_processor.go",
        "crush: 'min' declarado em batch_processor.go, parallel_processor.go"
      ],
      "non_fixable_reason": "ARCHITECTURAL",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\generate.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"MCP project generation initiated\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(generateCmd)\n    46 | \tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n    47 | \tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n    48 | \tgenerateCmd.MarkFlagRequired(\"template\")\n    49 | }\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(generateCmd)\n\tgenerateCmd.Flags().StringP(\"template\", \"t\", \"\", \"Template ID to use\")\n\tgenerateCmd.Flags().StringP(\"output\", \"o\", \".\", \"Output directory\")\n\tgenerateCmd.MarkFlagRequired(\"template\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\monitor.go",
          "line_number": 24,
          "code_snippet": "    19 | \t\tcmd.Println(\"System status: Operational\")\n    20 | \t\treturn nil\n    21 | \t},\n    22 | }\n    23 | \nâ†’   24 | func init() {\n    25 | \trootCmd.AddCommand(monitorCmd)\n    26 | }\n    27 | \n    28 | // SetMonitoringService sets the monitoring service\n    29 | func SetMonitoringService(service *services.MonitoringAppService) {\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(monitorCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\root.go",
          "line_number": 39,
          "code_snippet": "    34 | \t\tos.Exit(1)\n    35 | \t}\n    36 | }\n    37 | \n    38 | // init initializes the CLI\nâ†’   39 | func init() {\n    40 | \trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n    41 | \trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n    42 | \n    43 | \t// Add subcommand groups\n    44 | \trootCmd.AddCommand(analytics.AnalyticsCmd)\n",
          "full_function": "func init() {\n\trootCmd.PersistentFlags().BoolP(\"verbose\", \"v\", false, \"verbose output\")\n\trootCmd.PersistentFlags().String(\"config\", \"\", \"config file (default is $HOME/.hulk/config.yaml)\")\n\n\t// Add subcommand groups\n\trootCmd.AddCommand(analytics.AnalyticsCmd)\n\trootCmd.AddCommand(ci.CICmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "os",
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/analytics",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/cli/ci",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\state.go",
          "line_number": 20,
          "code_snippet": "    15 | \t\tcmd.Println(\"State management - service implementation pending\")\n    16 | \t\treturn nil\n    17 | \t},\n    18 | }\n    19 | \nâ†’   20 | func init() {\n    21 | \trootCmd.AddCommand(stateCmd)\n    22 | }\n    23 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(stateCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\template.go",
          "line_number": 44,
          "code_snippet": "    39 | \t\tcmd.Println(\"Template created\")\n    40 | \t\treturn nil\n    41 | \t},\n    42 | }\n    43 | \nâ†’   44 | func init() {\n    45 | \trootCmd.AddCommand(templateCmd)\n    46 | \ttemplateCmd.AddCommand(templateListCmd)\n    47 | \ttemplateCmd.AddCommand(templateCreateCmd)\n    48 | \ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n    49 | \ttemplateCreateCmd.MarkFlagRequired(\"name\")\n",
          "full_function": "func init() {\n\trootCmd.AddCommand(templateCmd)\n\ttemplateCmd.AddCommand(templateListCmd)\n\ttemplateCmd.AddCommand(templateCreateCmd)\n\ttemplateCreateCmd.Flags().StringP(\"name\", \"n\", \"\", \"Template name\")\n\ttemplateCreateCmd.MarkFlagRequired(\"name\")\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\version.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\tfmt.Printf(\"Version: %s\\n\", Version)\n    17 | \t\tfmt.Printf(\"Build Date: %s\\n\", BuildDate)\n    18 | \t},\n    19 | }\n    20 | \nâ†’   21 | func init() {\n    22 | \trootCmd.AddCommand(versionCmd)\n    23 | }\n    24 | \n",
          "full_function": "func init() {\n\trootCmd.AddCommand(versionCmd)\n}",
          "symbol_name": "init",
          "package_name": "cli",
          "dependencies": [
            "fmt",
            "github.com/spf13/cobra"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "Manager",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "parseParams",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\interfaces\\cli\\analytics\\performance.go",
          "line_number": 23,
          "code_snippet": "    18 | \t\tcmd.Println(\"  P95 Latency: 0ms\")\n    19 | \t\treturn nil\n    20 | \t},\n    21 | }\n    22 | \nâ†’   23 | func init() {\n    24 | \tAnalyticsCmd.AddCommand(performanceCmd)\n    25 | }\n    26 | \n",
          "full_function": "func init() {\n\tAnalyticsCmd.AddCommand(performanceCmd)\n}",
          "symbol_name": "init",
          "package_name": "analytics",
          "dependencies": [
            "github.com/spf13/cobra",
            "github.com/vertikon/mcp-core-inventory/pkg/logger"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "min",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "max",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 0,
        "affected_lines": 0,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "10-30 minutos",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    },
    {
      "type": "Codigo compila",
      "severity": "critical",
      "location": "multiplos arquivos",
      "description": "Nao compila: # github.com/vertikon/mcp-core-inventory/internal/mcp/protocol\ninternal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used\ninternal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in thi...",
      "suggestion": "Corrija os erros de compilacao listados",
      "fixability": {
        "safe": false,
        "rollback_easy": false,
        "affects_behavior": false,
        "requires_review": false,
        "non_fixable_reason": "BUSINESS_LOGIC",
        "tools": null,
        "executable_steps": null,
        "estimated_time": "Variavel - depende dos erros",
        "confidence": 0
      },
      "examples": [
        "ðŸ“„ Log completo: E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\docs\\validation\\raw\\2025-11-21-21-15-18-compilation.log",
        "",
        "# github.com/vertikon/mcp-core-inventory/internal/mcp/protocol",
        "internal\\mcp\\protocol\\router.go:6:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\router.go:215:6: parseParams redeclared in this block",
        "\tinternal\\mcp\\protocol\\handlers.go:779:6: other declaration of parseParams",
        "internal\\mcp\\protocol\\tools.go:358:64: undefined: protocol",
        "internal\\mcp\\protocol\\handlers.go:8:2: \"strings\" imported and not used",
        "internal\\mcp\\protocol\\handlers.go:345:4: h.parseParams undefined (type *ListTemplatesHandler has no field or method parseParams)",
        "internal\\mcp\\protocol\\handlers.go:447:4: h.parseParams undefined (type *ListProjectsHandler has no field or method parseParams)",
        "# github.com/vertikon/mcp-core-inventory/tools/generators",
        "tools\\generators\\mcp_generator.go:6:2: \"path/filepath\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/cmd/core-inventory",
        "cmd\\core-inventory\\main.go:17:2: nats redeclared in this block",
        "\tcmd\\core-inventory\\main.go:16:2: other declaration of nats",
        "cmd\\core-inventory\\main.go:19:2: redis redeclared in this block",
        "\tcmd\\core-inventory\\main.go:14:2: other declaration of redis",
        "cmd\\core-inventory\\main.go:21:2: http redeclared in this block",
        "\tcmd\\core-inventory\\main.go:8:2: other declaration of http",
        "cmd\\core-inventory\\main.go:90:22: undefined: redis.NewStockCache",
        "cmd\\core-inventory\\main.go:91:27: undefined: redis.NewReservationLock",
        "cmd\\core-inventory\\main.go:92:19: undefined: nats.NewEventPublisher",
        "cmd\\core-inventory\\main.go:104:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewConfirmReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:111:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.ReservationRepository value in argument to app.NewReleaseReservationUseCase: *postgres.LedgerRepository does not implement app.ReservationRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.Reservation) error",
        "cmd\\core-inventory\\main.go:117:3: cannot use ledgerRepo (variable of type *postgres.LedgerRepository) as app.MovementRepository value in argument to app.NewAdjustStockUseCase: *postgres.LedgerRepository does not implement app.MovementRepository (wrong type for method Save)",
        "\t\thave Save(context.Context, *ledger.StockLedger) error",
        "\t\twant Save(context.Context, *ledger.StockMovement) error",
        "cmd\\core-inventory\\main.go:143:17: undefined: http.NewRouter",
        "cmd\\core-inventory\\main.go:143:17: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/crush",
        "internal\\core\\crush\\parallel_processor.go:625:6: min redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:796:6: other declaration of min",
        "internal\\core\\crush\\parallel_processor.go:632:6: max redeclared in this block",
        "\tinternal\\core\\crush\\batch_processor.go:803:6: other declaration of max",
        "internal\\core\\crush\\batch_processor.go:269:19: undefined: runtime",
        "internal\\core\\crush\\batch_processor.go:427:6: declared and not used: id",
        "internal\\core\\crush\\batch_processor.go:560:18: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.AddInt64",
        "internal\\core\\crush\\batch_processor.go:584:42: cannot use \u0026bp.stats.TotalProcessingTime (value of type *time.Duration) as *int64 value in argument to atomic.LoadInt64",
        "internal\\core\\crush\\batch_processor.go:781:15: undefined: NewWorkerPool",
        "internal\\core\\crush\\batch_processor.go:792:23: too many arguments in call to abp.workerPool.Start",
        "\thave (context.Context)",
        "\twant ()",
        "internal\\core\\crush\\memory_optimizer.go:494:20: cannot use \u0026mo.stats.TotalMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: cannot use \u0026mo.stats.UsedMemoryMB (value of type *float64) as *int64 value in argument to atomic.StoreInt64",
        "internal\\core\\crush\\memory_optimizer.go:495:20: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/core/state",
        "internal\\core\\state\\distributed_store.go:543:22: invalid operation: cannot take address of dss.stats.LockWaitTime.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:649:31: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:651:21: invalid operation: cannot take address of dss.stats.AvgReadLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:656:31: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\distributed_store.go:658:21: invalid operation: cannot take address of dss.stats.AvgWriteLatency.Nanoseconds() (value of type int64)",
        "internal\\core\\state\\store.go:10:2: \"github.com/vertikon/mcp-core-inventory/pkg/logger\" imported and not used",
        "internal\\core\\state\\store.go:11:2: \"go.uber.org/zap\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/core/transformer",
        "internal\\core\\transformer\\feedforward.go:194:21: ffn.router undefined (type *FeedForwardNetwork has no field or method router)",
        "internal\\core\\transformer\\transformer.go:152:38: not enough arguments in call to t.embeddings.Forward",
        "\thave (*Tensor)",
        "\twant (context.Context, *Tensor)",
        "internal\\core\\transformer\\transformer.go:209:79: cannot use attentionMask (variable of type *Tensor) as *AttentionMask value in argument to l.attention.Forward",
        "internal\\core\\transformer\\transformer.go:215:28: cannot use attnOutput (variable of type *AttentionResult) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\transformer.go:249:65: cannot use ln.eps (variable of type float64) as *Tensor value in argument to t.add",
        "internal\\core\\transformer\\positional_encoding.go:6:2: \"fmt\" imported and not used",
        "# github.com/vertikon/mcp-core-inventory/internal/infrastructure/persistence/relational",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:198:2: declared and not used: knowledge",
        "internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go:203:9: undefined: knowledgePtr",
        "# github.com/vertikon/mcp-core-inventory/internal/state/cache",
        "internal\\state\\cache\\cache_coherency.go:162:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "internal\\state\\cache\\cache_coherency.go:217:11: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:253:34: cm.stats.TotalUpdates undefined (type *InvalidationStats has no field or method TotalUpdates)",
        "internal\\state\\cache\\cache_coherency.go:342:11: cm.cache.Delete undefined (type *StateCache is pointer to interface, not interface)",
        "# github.com/vertikon/mcp-core-inventory/internal/security/encryption",
        "internal\\security\\encryption\\encryption_manager.go:56:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\encryption_manager.go:64:3: unknown field keyManager in struct literal of type Manager",
        "internal\\security\\encryption\\encryption_manager.go:71:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\encryption_manager.go:81:16: m.keyManager undefined (type *Manager has no field or method keyManager)",
        "internal\\security\\encryption\\key_manager.go:52:6: Manager redeclared in this block",
        "\tinternal\\security\\encryption\\certificate_manager.go:42:6: other declaration of Manager",
        "internal\\security\\encryption\\key_manager.go:72:3: unknown field keyVersion in struct literal of type Manager",
        "internal\\security\\encryption\\key_manager.go:82:6: km.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:96:4: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:97:10: m.mu undefined (type *Manager has no field or method mu)",
        "internal\\security\\encryption\\key_manager.go:99:7: m.encryptionKey undefined (type *Manager has no field or method encryptionKey)",
        "internal\\security\\encryption\\key_manager.go:99:7: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/store",
        "internal\\state\\store\\conflict_resolver.go:236:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:238:10: not enough return values",
        "\thave (*VersionedState)",
        "\twant (*VersionedState, error)",
        "internal\\state\\store\\conflict_resolver.go:251:2: declared and not used: localTime",
        "internal\\state\\store\\conflict_resolver.go:252:2: declared and not used: remoteTime",
        "internal\\state\\store\\conflict_resolver.go:283:51: too many arguments in call to r.isMergeableValue",
        "\thave (interface{}, interface{})",
        "\twant (interface{})",
        "internal\\state\\store\\conflict_resolver.go:396:9: v declared and not used",
        "internal\\state\\store\\conflict_resolver.go:415:13: r.mergeMaps undefined (type map[string]interface{} has no field or method mergeMaps)",
        "internal\\state\\store\\conflict_resolver.go:419:13: r.mergeArrays undefined (type []interface{} has no field or method mergeArrays)",
        "internal\\state\\store\\conflict_resolver.go:516:35: cannot use localTS (variable of struct type time.Time) as uint64 value in argument to max",
        "internal\\state\\store\\conflict_resolver.go:622:6: max redeclared in this block",
        "\tinternal\\state\\store\\conflict_resolver.go:615:6: other declaration of max",
        "internal\\state\\store\\conflict_resolver.go:516:35: too many errors",
        "# github.com/vertikon/mcp-core-inventory/internal/state/events",
        "internal\\state\\events\\event_replay.go:249:2: declared and not used: snapshot",
        "internal\\state\\events\\event_replay.go:290:2: declared and not used: events",
        "internal\\state\\events\\event_versioning.go:140:4: invalid operation: cannot call copy (variable of struct type VersionInfo): VersionInfo is not a function",
        "internal\\state\\events\\event_versioning.go:216:30: ev.resolveVersionConflict undefined (type *EventVersioningImpl has no field or method resolveVersionConflict, but does have method ResolveVersionConflict)",
        ""
      ],
      "non_fixable_reason": "BUSINESS_LOGIC",
      "code_contexts": [
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 6,
          "code_snippet": "     1 | package protocol\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"strings\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n     9 | \t\"go.uber.org/zap\"\n    10 | )\n    11 | \n",
          "full_function": "\t\"strings\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// ToolRouter handles routing of MCP tool requests to appropriate handlers\ntype ToolRouter struct {\n\thandlers map[string]ToolHandler\n\tlogger   *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\router.go",
          "line_number": 215,
          "code_snippet": "   210 | \n   211 | \treturn nil\n   212 | }\n   213 | \n   214 | // parseParams parses parameters from a JSON-RPC request\nâ†’  215 | func parseParams(params interface{}, target interface{}) error {\n   216 | \tif params == nil {\n   217 | \t\treturn nil\n   218 | \t}\n   219 | \n   220 | \t// This is a simplified parameter parsing\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "strings",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\mcp\\protocol\\handlers.go",
          "line_number": 779,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\tools.go",
          "line_number": 358,
          "code_snippet": "   353 | func (h *ToolHandlerImpl) Schema() map[string]interface{} {\n   354 | \treturn h.schema\n   355 | }\n   356 | \n   357 | // Handle processes the tool request\nâ†’  358 | func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n   359 | \th.logger.Info(\"Handling tool request\",\n   360 | \t\tzap.String(\"tool\", h.name),\n   361 | \t\tzap.Any(\"params\", request.Params))\n   362 | \n   363 | \t// This is a placeholder implementation\n",
          "full_function": "func (h *ToolHandlerImpl) Handle(ctx context.Context, request *protocol.JSONRPCRequest) (*protocol.JSONRPCResponse, error) {\n\th.logger.Info(\"Handling tool request\",\n\t\tzap.String(\"tool\", h.name),\n\t\tzap.Any(\"params\", request.Params))\n\n\t// This is a placeholder implementation\n\t// In a real implementation, each tool would have its own handler logic\n\tresult := map[string]interface{}{\n\t\t\"tool\":    h.name,\n\t\t\"status\":  \"implemented\",\n\t\t\"message\": fmt.Sprintf(\"Tool %s is ready for implementation\", h.name),\n\t}\n\n\treturn NewSuccessResponse(request.ID, result), nil\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "fmt",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 8,
          "code_snippet": "     3 | import (\n     4 | \t\"context\"\n     5 | \t\"encoding/json\"\n     6 | \t\"fmt\"\n     7 | \t\"os\"\nâ†’    8 | \t\"strings\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n    12 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n    13 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n",
          "full_function": "\t\"strings\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/registry\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/validators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// HandlerManager manages all MCP tool handlers\ntype HandlerManager struct {\n\tgeneratorFactory *generators.GeneratorFactory\n\tvalidatorFactory *validators.ValidatorFactory\n\tregistry         *registry.MCPRegistry\n\tlogger           *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 345,
          "code_snippet": "   340 | \tvar params struct {\n   341 | \t\tStack    string `json:\"stack,omitempty\"`\n   342 | \t\tCategory string `json:\"category,omitempty\"`\n   343 | \t}\n   344 | \nâ†’  345 | \th.parseParams(request.Params, \u0026params)\n   346 | \n   347 | \ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n   348 | \t\tStack:    params.Stack,\n   349 | \t\tCategory: params.Category,\n   350 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\ttemplates, err := h.registry.ListTemplates(registry.TemplateFilter{\n\t\tStack:    params.Stack,\n\t\tCategory: params.Category,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\mcp\\protocol\\handlers.go",
          "line_number": 447,
          "code_snippet": "   442 | \tvar params struct {\n   443 | \t\tStack  string `json:\"stack,omitempty\"`\n   444 | \t\tStatus string `json:\"status,omitempty\"`\n   445 | \t}\n   446 | \nâ†’  447 | \th.parseParams(request.Params, \u0026params)\n   448 | \n   449 | \tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n   450 | \t\tStack:  params.Stack,\n   451 | \t\tStatus: params.Status,\n   452 | \t})\n",
          "full_function": "\th.parseParams(request.Params, \u0026params)\n\n\tprojects, err := h.registry.ListProjects(registry.ProjectFilter{\n\t\tStack:  params.Stack,\n\t\tStatus: params.Status,\n\t})",
          "symbol_name": "",
          "package_name": "protocol",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "os",
            "strings",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/registry",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/validators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\tools\\generators\\mcp_generator.go",
          "line_number": 6,
          "code_snippet": "     1 | package generators\n     2 | \n     3 | import (\n     4 | \t\"context\"\n     5 | \t\"fmt\"\nâ†’    6 | \t\"path/filepath\"\n     7 | \n     8 | \t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n     9 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    10 | \t\"go.uber.org/zap\"\n    11 | )\n",
          "full_function": "\t\"path/filepath\"\n\n\t\"github.com/vertikon/mcp-core-inventory/internal/mcp/generators\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// MCPGenerator orchestrates MCP generation using internal/mcp/generators\n// This is the CLI/Tool interface for generating MCPs\ntype MCPGenerator struct {\n\tfactory *generators.GeneratorFactory\n\tlogger  *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "generators",
          "dependencies": [
            "context",
            "fmt",
            "path/filepath",
            "github.com/vertikon/mcp-core-inventory/internal/mcp/generators",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 17,
          "code_snippet": "    12 | \t\"time\"\n    13 | \n    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\nâ†’   17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 16,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 19,
          "code_snippet": "    14 | \t\"github.com/go-redis/redis/v8\"\n    15 | \t_ \"github.com/lib/pq\"\n    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\nâ†’   19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n    21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/app\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 14,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 21,
          "code_snippet": "    16 | \t\"github.com/nats-io/nats.go\"\n    17 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/nats\"\n    18 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/postgres\"\n    19 | \t\"github.com/vertikon/mcp-core-inventory/internal/adapters/redis\"\n    20 | \t\"github.com/vertikon/mcp-core-inventory/internal/app\"\nâ†’   21 | \t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n    22 | \t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n    23 | \t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n    24 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    25 | \t\"go.uber.org/zap\"\n    26 | )\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/internal/interfaces/http\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/observability\"\n\t\"github.com/vertikon/mcp-core-inventory/internal/services\"\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\nfunc main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tcmd\\core-inventory\\main.go",
          "line_number": 8,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 90,
          "code_snippet": "    85 | \t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\nâ†’   90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 91,
          "code_snippet": "    86 | \t}\n    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\nâ†’   91 | \treservationLock := redis.NewReservationLock(rdb)\n    92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 92,
          "code_snippet": "    87 | \n    88 | \t// Initialize repositories and services\n    89 | \tledgerRepo := postgres.NewLedgerRepository(db)\n    90 | \tstockCache := redis.NewStockCache(rdb)\n    91 | \treservationLock := redis.NewReservationLock(rdb)\nâ†’   92 | \teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n    93 | \n    94 | \t// Initialize use cases\n    95 | \treserveUseCase := app.NewReserveStockUseCase(\n    96 | \t\tledgerRepo,\n    97 | \t\treservationLock,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 104,
          "code_snippet": "    99 | \t\tlogger.GetLogger(),\n   100 | \t)\n   101 | \n   102 | \tconfirmUseCase := app.NewConfirmReservationUseCase(\n   103 | \t\tledgerRepo,\nâ†’  104 | \t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n   105 | \t\teventPub,\n   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 111,
          "code_snippet": "   106 | \t\tlogger.GetLogger(),\n   107 | \t)\n   108 | \n   109 | \treleaseUseCase := app.NewReleaseReservationUseCase(\n   110 | \t\tledgerRepo,\nâ†’  111 | \t\tledgerRepo,\n   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 117,
          "code_snippet": "   112 | \t\tlogger.GetLogger(),\n   113 | \t)\n   114 | \n   115 | \tadjustUseCase := app.NewAdjustStockUseCase(\n   116 | \t\tledgerRepo,\nâ†’  117 | \t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n   118 | \t\tlogger.GetLogger(),\n   119 | \t)\n   120 | \n   121 | \tqueryUseCase := app.NewQueryAvailableUseCase(\n   122 | \t\tledgerRepo,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\cmd\\core-inventory\\main.go",
          "line_number": 143,
          "code_snippet": "   138 | \tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n   139 | \tdefer cleanupCancel()\n   140 | \tgo cleanupService.Start(cleanupCtx)\n   141 | \n   142 | \t// Setup HTTP router\nâ†’  143 | \trouter := http.NewRouter(\n   144 | \t\treserveUseCase,\n   145 | \t\tconfirmUseCase,\n   146 | \t\treleaseUseCase,\n   147 | \t\tadjustUseCase,\n   148 | \t\tqueryUseCase,\n",
          "full_function": "func main() {\n\t// Initialize logger\n\tif err := logger.Init(\"info\", true); err != nil {\n\t\tfmt.Fprintf(os.Stderr, \"Failed to initialize logger: %v\\n\", err)\n\t\tos.Exit(1)\n\t}\n\tdefer logger.Sync()\n\n\tlogger.Info(\"Starting mcp-core-inventory\")\n\n\t// Load configuration from environment\n\tdbURL := os.Getenv(\"DATABASE_URL\")\n\tif dbURL == \"\" {\n\t\tdbURL = \"postgres://user:password@localhost/inventory?sslmode=disable\"\n\t}\n\n\tredisURL := os.Getenv(\"REDIS_URL\")\n\tif redisURL == \"\" {\n\t\tredisURL = \"localhost:6379\"\n\t}\n\n\tnatsURL := os.Getenv(\"NATS_URL\")\n\tif natsURL == \"\" {\n\t\tnatsURL = \"nats://localhost:4222\"\n\t}\n\n\t// Connect to PostgreSQL\n\tdb, err := sql.Open(\"postgres\", dbURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to database\", zap.Error(err))\n\t}\n\tdefer db.Close()\n\n\tif err := db.Ping(); err != nil {\n\t\tlogger.Fatal(\"Failed to ping database\", zap.Error(err))\n\t}\n\n\t// Connect to Redis\n\trdb := redis.NewClient(\u0026redis.Options{\n\t\tAddr: redisURL,\n\t})\n\tdefer rdb.Close()\n\n\tctx := context.Background()\n\tif err := rdb.Ping(ctx).Err(); err != nil {\n\t\tlogger.Fatal(\"Failed to connect to Redis\", zap.Error(err))\n\t}\n\n\t// Connect to NATS\n\tnc, err := nats.Connect(natsURL)\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to connect to NATS\", zap.Error(err))\n\t}\n\tdefer nc.Close()\n\n\tjs, err := nc.JetStream()\n\tif err != nil {\n\t\tlogger.Fatal(\"Failed to get JetStream context\", zap.Error(err))\n\t}\n\n\t// Initialize repositories and services\n\tledgerRepo := postgres.NewLedgerRepository(db)\n\tstockCache := redis.NewStockCache(rdb)\n\treservationLock := redis.NewReservationLock(rdb)\n\teventPub := nats.NewEventPublisher(js, logger.GetLogger())\n\n\t// Initialize use cases\n\treserveUseCase := app.NewReserveStockUseCase(\n\t\tledgerRepo,\n\t\treservationLock,\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\tconfirmUseCase := app.NewConfirmReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // ReservationRepository is same as LedgerRepository for now\n\t\teventPub,\n\t\tlogger.GetLogger(),\n\t)\n\n\treleaseUseCase := app.NewReleaseReservationUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t)\n\n\tadjustUseCase := app.NewAdjustStockUseCase(\n\t\tledgerRepo,\n\t\tledgerRepo, // MovementRepository is same as LedgerRepository for now\n\t\tlogger.GetLogger(),\n\t)\n\n\tqueryUseCase := app.NewQueryAvailableUseCase(\n\t\tledgerRepo,\n\t\tstockCache,\n\t)\n\n\t// Initialize metrics\n\tinventoryMetrics := observability.NewInventoryMetrics()\n\n\t// Initialize reservation cleanup service\n\tcleanupService := services.NewReservationCleanupService(\n\t\tledgerRepo,\n\t\tledgerRepo,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\t// Start cleanup service in background\n\tcleanupCtx, cleanupCancel := context.WithCancel(context.Background())\n\tdefer cleanupCancel()\n\tgo cleanupService.Start(cleanupCtx)\n\n\t// Setup HTTP router\n\trouter := http.NewRouter(\n\t\treserveUseCase,\n\t\tconfirmUseCase,\n\t\treleaseUseCase,\n\t\tadjustUseCase,\n\t\tqueryUseCase,\n\t\tlogger.GetLogger(),\n\t\tinventoryMetrics,\n\t)\n\n\tmux := http.NewServeMux()\n\trouter.SetupRoutes(mux)\n\n\t// Start HTTP server\n\tport := os.Getenv(\"PORT\")\n\tif port == \"\" {\n\t\tport = \"8080\"\n\t}\n\n\tserver := \u0026http.Server{\n\t\tAddr:         \":\" + port,\n\t\tHandler:      mux,\n\t\tReadTimeout:  15 * time.Second,\n\t\tWriteTimeout: 15 * time.Second,\n\t}\n\n\tgo func() {\n\t\tlogger.Info(\"HTTP server starting\", zap.String(\"port\", port))\n\t\tif err := server.ListenAndServe(); err != nil \u0026\u0026 err != http.ErrServerClosed {\n\t\t\tlogger.Fatal(\"HTTP server error\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// Wait for interrupt signal\n\tsigChan := make(chan os.Signal, 1)\n\tsignal.Notify(sigChan, os.Interrupt, syscall.SIGTERM)\n\t\u003c-sigChan\n\n\tlogger.Info(\"Shutting down server\")\n\n\t// Graceful shutdown\n\tshutdownCtx, shutdownCancel := context.WithTimeout(context.Background(), 30*time.Second)\n\tdefer shutdownCancel()\n\n\tif err := server.Shutdown(shutdownCtx); err != nil {\n\t\tlogger.Error(\"Error during server shutdown\", zap.Error(err))\n\t}\n\n\tlogger.Info(\"Server stopped\")\n}",
          "symbol_name": "",
          "package_name": "main",
          "dependencies": [
            "context",
            "database/sql",
            "fmt",
            "net/http",
            "os",
            "os/signal",
            "syscall",
            "time",
            "github.com/go-redis/redis/v8",
            "\"github.com/lib/pq",
            "github.com/nats-io/nats.go",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/nats",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/postgres",
            "github.com/vertikon/mcp-core-inventory/internal/adapters/redis",
            "github.com/vertikon/mcp-core-inventory/internal/app",
            "github.com/vertikon/mcp-core-inventory/internal/interfaces/http",
            "github.com/vertikon/mcp-core-inventory/internal/observability",
            "github.com/vertikon/mcp-core-inventory/internal/services",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 625,
          "code_snippet": "   620 | \tas.stats.ScaleDownEvents++\n   621 | \tnow := time.Now()\n   622 | \tas.stats.LastScalingTime = \u0026now\n   623 | }\n   624 | \nâ†’  625 | func min(a, b int) int {\n   626 | \tif a \u003c b {\n   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n",
          "full_function": "func min(a, b int) int {\n\tif a \u003c b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 796,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\parallel_processor.go",
          "line_number": 632,
          "code_snippet": "   627 | \t\treturn a\n   628 | \t}\n   629 | \treturn b\n   630 | }\n   631 | \nâ†’  632 | func max(a, b int) int {\n   633 | \tif a \u003e b {\n   634 | \t\treturn a\n   635 | \t}\n   636 | \treturn b\n   637 | }\n",
          "full_function": "func max(a, b int) int {\n\tif a \u003e b {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\core\\crush\\batch_processor.go",
          "line_number": 803,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 269,
          "code_snippet": "   264 | \n   265 | \t// Initialize async processor\n   266 | \tif config.EnableAsync {\n   267 | \t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n   268 | \t\t\tEnabled:       true,\nâ†’  269 | \t\t\tNumWorkers:    runtime.NumCPU(),\n   270 | \t\t\tQueueSize:     100,\n   271 | \t\t\tWorkerTimeout: config.Timeout,\n   272 | \t\t\tRetryAttempts: 3,\n   273 | \t\t})\n   274 | \t}\n",
          "full_function": "func NewBatchProcessor(config BatchProcessorConfig) *BatchProcessor {\n\tif config.MaxBatchSize == 0 {\n\t\tconfig.MaxBatchSize = 32\n\t}\n\tif config.MinBatchSize == 0 {\n\t\tconfig.MinBatchSize = 1\n\t}\n\tif config.Timeout == 0 {\n\t\tconfig.Timeout = 5 * time.Second\n\t}\n\n\tlogger.Info(\"Creating batch processor\",\n\t\tzap.Int(\"max_batch_size\", config.MaxBatchSize),\n\t\tzap.Int(\"min_batch_size\", config.MinBatchSize),\n\t\tzap.Duration(\"timeout\", config.Timeout),\n\t\tzap.Bool(\"dynamic_batching\", config.EnableDynamicBatching),\n\t\tzap.Bool(\"prefetch\", config.EnablePrefetch),\n\t\tzap.Bool(\"async\", config.EnableAsync),\n\t)\n\n\tctx, cancel := context.WithCancel(context.Background())\n\n\tprocessor := \u0026BatchProcessor{\n\t\tconfig:      config,\n\t\tbatches:     make(map[string]*Batch),\n\t\tbatchQueue:  make(chan *Batch, 100),\n\t\tresultQueue: make(chan *BatchResult, 100),\n\t\tctx:         ctx,\n\t\tcancel:      cancel,\n\t\tstats:       \u0026BatchProcessorStats{},\n\t}\n\n\t// Initialize dynamic sizing\n\tif config.EnableDynamicBatching {\n\t\tprocessor.dynamicSizing = NewDynamicBatchSizer(DynamicSizingConfig{\n\t\t\tEnabled:       true,\n\t\t\tStrategy:      StrategyAdaptive,\n\t\t\tMinSize:       config.MinBatchSize,\n\t\t\tMaxSize:       config.MaxBatchSize,\n\t\t\tTargetLatency: config.MaxLatency,\n\t\t})\n\t}\n\n\t// Initialize prefetcher\n\tif config.EnablePrefetch {\n\t\tprocessor.prefetcher = NewBatchPrefetcher(PrefetchConfig{\n\t\t\tEnabled:        true,\n\t\t\tPrefetchSize:   config.MaxBatchSize,\n\t\t\tCacheSize:      100,\n\t\t\tPrefetchPolicy: PolicyPredictive,\n\t\t})\n\t}\n\n\t// Initialize async processor\n\tif config.EnableAsync {\n\t\tprocessor.asyncProcessor = NewAsyncBatchProcessor(AsyncProcessingConfig{\n\t\t\tEnabled:       true,\n\t\t\tNumWorkers:    runtime.NumCPU(),\n\t\t\tQueueSize:     100,\n\t\t\tWorkerTimeout: config.Timeout,\n\t\t\tRetryAttempts: 3,\n\t\t})\n\t}\n\n\treturn processor\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 427,
          "code_snippet": "   422 | func (bp *BatchProcessor) checkBatchTimeouts() {\n   423 | \tbp.mu.Lock()\n   424 | \tdefer bp.mu.Unlock()\n   425 | \n   426 | \tnow := time.Now()\nâ†’  427 | \tfor id, batch := range bp.batches {\n   428 | \t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n   429 | \t\t\tbp.submitBatch(batch)\n   430 | \t\t}\n   431 | \t}\n   432 | }\n",
          "full_function": "func (bp *BatchProcessor) checkBatchTimeouts() {\n\tbp.mu.Lock()\n\tdefer bp.mu.Unlock()\n\n\tnow := time.Now()\n\tfor id, batch := range bp.batches {\n\t\tif now.Sub(batch.CreatedAt) \u003e= batch.Timeout \u0026\u0026 len(batch.Items) \u003e 0 {\n\t\t\tbp.submitBatch(batch)\n\t\t}\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 560,
          "code_snippet": "   555 | // updateStats updates batch processing statistics\n   556 | func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n   557 | \tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n   558 | \tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n   559 | \tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\nâ†’  560 | \tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n   561 | \n   562 | \tif len(result.Errors) \u003e 0 {\n   563 | \t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n   564 | \t}\n   565 | }\n",
          "full_function": "func (bp *BatchProcessor) updateStats(batch *Batch, result *BatchResult) {\n\tatomic.AddInt64(\u0026bp.stats.TotalBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalItems, int64(batch.Size))\n\tatomic.AddInt64(\u0026bp.stats.CompletedBatches, 1)\n\tatomic.AddInt64(\u0026bp.stats.TotalProcessingTime, int64(result.Duration))\n\n\tif len(result.Errors) \u003e 0 {\n\t\tatomic.AddInt64(\u0026bp.stats.FailedBatches, 1)\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 584,
          "code_snippet": "   579 | \t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n   580 | \t}\n   581 | \n   582 | \t// Calculate average processing time\n   583 | \tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\nâ†’  584 | \ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n   585 | \n   586 | \tif completedBatches \u003e 0 {\n   587 | \t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n   588 | \t}\n   589 | \n",
          "full_function": "func (bp *BatchProcessor) collectStats() {\n\tbp.stats.LastUpdated = time.Now()\n\n\t// Calculate queue utilization\n\tbp.stats.QueueUtilization = float64(len(bp.batchQueue)) / float64(cap(bp.batchQueue))\n\n\t// Calculate average batch size\n\ttotalBatches := atomic.LoadInt64(\u0026bp.stats.TotalBatches)\n\ttotalItems := atomic.LoadInt64(\u0026bp.stats.TotalItems)\n\n\tif totalBatches \u003e 0 {\n\t\tbp.stats.AvgBatchSize = float64(totalItems) / float64(totalBatches)\n\t}\n\n\t// Calculate average processing time\n\tcompletedBatches := atomic.LoadInt64(\u0026bp.stats.CompletedBatches)\n\ttotalProcessingTime := atomic.LoadInt64(\u0026bp.stats.TotalProcessingTime)\n\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.AvgProcessingTime = time.Duration(totalProcessingTime / completedBatches)\n\t}\n\n\t// Calculate throughput\n\tif completedBatches \u003e 0 {\n\t\tbp.stats.Throughput = float64(totalItems) / time.Since(time.Now()).Seconds()\n\t}\n\n\tlogger.Debug(\"Batch processor stats\",\n\t\tzap.Float64(\"queue_utilization\", bp.stats.QueueUtilization),\n\t\tzap.Float64(\"avg_batch_size\", bp.stats.AvgBatchSize),\n\t\tzap.Duration(\"avg_processing_time\", bp.stats.AvgProcessingTime),\n\t\tzap.Float64(\"throughput\", bp.stats.Throughput),\n\t)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 781,
          "code_snippet": "   776 | \n   777 | // NewAsyncBatchProcessor creates a new async batch processor\n   778 | func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n   779 | \treturn \u0026AsyncBatchProcessor{\n   780 | \t\tconfig:     config,\nâ†’  781 | \t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n   782 | \t\tstats:      \u0026AsyncProcessingStats{},\n   783 | \t}\n   784 | }\n   785 | \n   786 | // Start starts async batch processor\n",
          "full_function": "func NewAsyncBatchProcessor(config AsyncProcessingConfig) *AsyncBatchProcessor {\n\treturn \u0026AsyncBatchProcessor{\n\t\tconfig:     config,\n\t\tworkerPool: NewWorkerPool(config.NumWorkers, config.QueueSize, config.WorkerTimeout),\n\t\tstats:      \u0026AsyncProcessingStats{},\n\t}\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\batch_processor.go",
          "line_number": 792,
          "code_snippet": "   787 | func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n   788 | \tif !abp.config.Enabled {\n   789 | \t\treturn\n   790 | \t}\n   791 | \nâ†’  792 | \tabp.workerPool.Start(ctx)\n   793 | }\n   794 | \n   795 | // Additional helper functions\n   796 | func min(a, b int) int {\n   797 | \tif a \u003c b {\n",
          "full_function": "func (abp *AsyncBatchProcessor) Start(ctx context.Context) {\n\tif !abp.config.Enabled {\n\t\treturn\n\t}\n\n\tabp.workerPool.Start(ctx)\n}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 494,
          "code_snippet": "   489 | \t\ttotalMemory += segment.Size\n   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \nâ†’  494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n   495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\crush\\memory_optimizer.go",
          "line_number": 495,
          "code_snippet": "   490 | \t}\n   491 | \n   492 | \ttotalMemory += usedMemory\n   493 | \n   494 | \tatomic.StoreInt64(\u0026mo.stats.TotalMemoryMB, int64(float64(totalMemory)/1024/1024))\nâ†’  495 | \tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n   496 | \tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n   497 | \n   498 | \t// Update hit/miss rates\n   499 | \ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n   500 | \tif totalRequests \u003e 0 {\n",
          "full_function": "\tatomic.StoreInt64(\u0026mo.stats.UsedMemoryMB, int64(float64(usedMemory)/1024/1024))\n\tatomic.StoreInt64(\u0026mo.stats.FreeMemoryMB, int64(float64(totalMemory-usedMemory)/1024/1024))\n\n\t// Update hit/miss rates\n\ttotalRequests := atomic.LoadInt64(\u0026mo.stats.UsedSegments) + atomic.LoadInt64(\u0026mo.stats.Evictions)\n\tif totalRequests \u003e 0 {\n\t\thitRate := float64(atomic.LoadInt64(\u0026mo.stats.UsedSegments)) / float64(totalRequests)\n\t\tmissRate := float64(atomic.LoadInt64(\u0026mo.stats.Evictions)) / float64(totalRequests)\n\n\t\t// These are simplified calculations\n\t\tlogger.Debug(\"Memory pool statistics\",\n\t\t\tzap.Float64(\"hit_rate\", hitRate),\n\t\t\tzap.Float64(\"miss_rate\", missRate),\n\t\t\tzap.Float64(\"used_memory_mb\", float64(usedMemory)/1024/1024),\n\t\t)\n\t}",
          "symbol_name": "",
          "package_name": "crush",
          "dependencies": [
            "context",
            "fmt",
            "runtime",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 543,
          "code_snippet": "   538 | \t}\n   539 | \n   540 | \tstart := time.Now()\n   541 | \tdefer func() {\n   542 | \t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\nâ†’  543 | \t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n   544 | \t}()\n   545 | \n   546 | \t// Try remote store first\n   547 | \tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n   548 | \tif err == nil {\n",
          "full_function": "func (dss *DistributedStateStore) Lock(ctx context.Context, key string, ttl time.Duration) (*Lock, error) {\n\tif !dss.config.EnableLocking {\n\t\treturn nil, fmt.Errorf(\"locking is not enabled\")\n\t}\n\n\tstart := time.Now()\n\tdefer func() {\n\t\tatomic.AddInt64(\u0026dss.stats.LockOperations, 1)\n\t\tatomic.StoreInt64(\u0026dss.stats.LockWaitTime.Nanoseconds(), time.Since(start).Nanoseconds())\n\t}()\n\n\t// Try remote store first\n\tlock, err := dss.remoteStore.Lock(ctx, key, ttl)\n\tif err == nil {\n\t\treturn lock, nil\n\t}\n\n\t// Fallback to local store\n\treturn dss.localStore.Lock(ctx, key, ttl)\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 649,
          "code_snippet": "   644 | \treturn *dss.stats\n   645 | }\n   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\nâ†’  649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 651,
          "code_snippet": "   646 | \n   647 | // updateReadLatency updates read latency statistics\n   648 | func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n   649 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n   650 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n",
          "full_function": "func (dss *DistributedStateStore) updateReadLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 656,
          "code_snippet": "   651 | \tatomic.StoreInt64(\u0026dss.stats.AvgReadLatency.Nanoseconds(), int64(newAvg))\n   652 | }\n   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\nâ†’  656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n   658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\distributed_store.go",
          "line_number": 658,
          "code_snippet": "   653 | \n   654 | // updateWriteLatency updates write latency statistics\n   655 | func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n   656 | \tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n   657 | \tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\nâ†’  658 | \tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n   659 | }\n   660 | \n   661 | // NewMemoryStateStore creates a new in-memory state store\n   662 | func NewMemoryStateStore() *MemoryStateStore {\n   663 | \treturn \u0026MemoryStateStore{\n",
          "full_function": "func (dss *DistributedStateStore) updateWriteLatency(latency time.Duration) {\n\tcurrent := atomic.LoadInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds())\n\tnewAvg := time.Duration((int64(current) + int64(latency.Nanoseconds())) / 2)\n\tatomic.StoreInt64(\u0026dss.stats.AvgWriteLatency.Nanoseconds(), int64(newAvg))\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "fmt",
            "sync",
            "sync/atomic",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 10,
          "code_snippet": "     5 | \t\"context\"\n     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\nâ†’   10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n    11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n",
          "full_function": "\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\state\\store.go",
          "line_number": 11,
          "code_snippet": "     6 | \t\"encoding/json\"\n     7 | \t\"time\"\n     8 | \n     9 | \t\"github.com/dgraph-io/badger/v4\"\n    10 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\nâ†’   11 | \t\"go.uber.org/zap\"\n    12 | )\n    13 | \n    14 | // Store provides persistent state storage using BadgerDB\n    15 | type Store struct {\n    16 | \tdb *badger.DB\n",
          "full_function": "\t\"go.uber.org/zap\"\n)\n\n// Store provides persistent state storage using BadgerDB\ntype Store struct {\n\tdb *badger.DB\n}",
          "symbol_name": "",
          "package_name": "state",
          "dependencies": [
            "context",
            "encoding/json",
            "time",
            "github.com/dgraph-io/badger/v4",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\feedforward.go",
          "line_number": 194,
          "code_snippet": "   189 | }\n   190 | \n   191 | // forwardMoE performs mixture of experts computation\n   192 | func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n   193 | \t// Router determines which experts to use\nâ†’  194 | \trouter, err := ffn.router.Forward(input)\n   195 | \tif err != nil {\n   196 | \t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n   197 | \t}\n   198 | \n   199 | \t// Select top-k experts\n",
          "full_function": "func (ffn *FeedForwardNetwork) forwardMoE(ctx context.Context, input *Tensor) (*Tensor, error) {\n\t// Router determines which experts to use\n\trouter, err := ffn.router.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"routing error: %w\", err)\n\t}\n\n\t// Select top-k experts\n\tselectedExperts := ffn.selectTopKExperts(router)\n\n\t// Combine expert outputs\n\toutput := ffn.combineExperts(input, selectedExperts)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 152,
          "code_snippet": "   147 | \t\treturn nil, ctx.Err()\n   148 | \tdefault:\n   149 | \t}\n   150 | \n   151 | \t// Embedding layer\nâ†’  152 | \thidden, err := t.embeddings.Forward(input)\n   153 | \tif err != nil {\n   154 | \t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n   155 | \t}\n   156 | \n   157 | \t// Add positional encoding\n",
          "full_function": "func (t *GLMTransformer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tt.mu.RLock()\n\tdefer t.mu.RUnlock()\n\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Embedding layer\n\thidden, err := t.embeddings.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"embedding error: %w\", err)\n\t}\n\n\t// Add positional encoding\n\tif t.posEncoding != nil {\n\t\tposEncoded, err := t.posEncoding.Forward(ctx, hidden, 0)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"positional encoding error: %w\", err)\n\t\t}\n\t\thidden = posEncoded\n\t}\n\n\t// Pass through transformer layers\n\tfor i, layer := range t.layers {\n\t\tselect {\n\t\tcase \u003c-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\tlayerOutput, err := layer.Forward(ctx, hidden, attentionMask)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"layer %d error: %w\", i, err)\n\t\t}\n\t\thidden = layerOutput\n\n\t\tlogger.Debug(\"Transformer layer processed\",\n\t\t\tzap.Int(\"layer\", i),\n\t\t\tzap.Float64(\"mean_activation\", t.meanActivation(hidden)),\n\t\t)\n\t}\n\n\t// Final layer norm\n\toutput, err := t.layernorm.Forward(hidden)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"final layer norm error: %w\", err)\n\t}\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 209,
          "code_snippet": "   204 | \tnormInput, err := l.layernorm1.Forward(input)\n   205 | \tif err != nil {\n   206 | \t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n   207 | \t}\n   208 | \nâ†’  209 | \tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 215,
          "code_snippet": "   210 | \tif err != nil {\n   211 | \t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n   212 | \t}\n   213 | \n   214 | \t// Residual connection\nâ†’  215 | \tresidual1 := t.add(input, attnOutput)\n   216 | \n   217 | \t// Pre-norm + feed-forward\n   218 | \tnormResidual, err := l.layernorm2.Forward(residual1)\n   219 | \tif err != nil {\n   220 | \t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n",
          "full_function": "func (l *TransformerLayer) Forward(ctx context.Context, input *Tensor, attentionMask *Tensor) (*Tensor, error) {\n\tselect {\n\tcase \u003c-ctx.Done():\n\t\treturn nil, ctx.Err()\n\tdefault:\n\t}\n\n\t// Pre-norm + attention\n\tnormInput, err := l.layernorm1.Forward(input)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"pre-norm error: %w\", err)\n\t}\n\n\tattnOutput, err := l.attention.Forward(ctx, normInput, normInput, normInput, attentionMask)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"attention error: %w\", err)\n\t}\n\n\t// Residual connection\n\tresidual1 := t.add(input, attnOutput)\n\n\t// Pre-norm + feed-forward\n\tnormResidual, err := l.layernorm2.Forward(residual1)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"post-norm error: %w\", err)\n\t}\n\n\tffOutput, err := l.feedForward.Forward(ctx, normResidual)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"feed-forward error: %w\", err)\n\t}\n\n\t// Residual connection\n\toutput := t.add(residual1, ffOutput)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\transformer.go",
          "line_number": 249,
          "code_snippet": "   244 | // Forward performs layer normalization\n   245 | func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n   246 | \t// Simplified layer norm implementation\n   247 | \tmean := t.mean(input, -1, true)\n   248 | \tvariance := t.variance(input, -1, true)\nâ†’  249 | \tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n   250 | \n   251 | \t// Scale and shift\n   252 | \toutput := t.mul(normalized, ln.weight)\n   253 | \toutput = t.add(output, ln.bias)\n   254 | \n",
          "full_function": "func (ln *LayerNorm) Forward(input *Tensor) (*Tensor, error) {\n\t// Simplified layer norm implementation\n\tmean := t.mean(input, -1, true)\n\tvariance := t.variance(input, -1, true)\n\tnormalized := t.div(t.sub(input, mean), t.sqrt(t.add(variance, ln.eps)))\n\n\t// Scale and shift\n\toutput := t.mul(normalized, ln.weight)\n\toutput = t.add(output, ln.bias)\n\n\treturn output, nil\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\core\\transformer\\positional_encoding.go",
          "line_number": 6,
          "code_snippet": "     1 | // Package transformer implements positional encoding for GLM-4.6\n     2 | package transformer\n     3 | \n     4 | import (\n     5 | \t\"context\"\nâ†’    6 | \t\"fmt\"\n     7 | \t\"math\"\n     8 | \t\"sync\"\n     9 | \t\"time\"\n    10 | \n    11 | \t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n",
          "full_function": "\t\"fmt\"\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/vertikon/mcp-core-inventory/pkg/logger\"\n\t\"go.uber.org/zap\"\n)\n\n// PositionalEncodingType represents different positional encoding approaches\ntype PositionalEncodingType string\n\nconst (\n\tPosEncodingTypeSinusoidal PositionalEncodingType = \"sinusoidal\"\n\tPosEncodingTypeLearned    PositionalEncodingType = \"learned\"\n\tPosEncodingTypeRelative   PositionalEncodingType = \"relative\"\n\tPosEncodingTypeRotary     PositionalEncodingType = \"rotary\"\n\tPosEncodingTypeALiBi      PositionalEncodingType = \"alibi\"\n\tPosEncodingTypeXPos       PositionalEncodingType = \"xpos\"\n)\n\n// PositionalEncodingConfig represents positional encoding configuration\ntype PositionalEncodingConfig struct {\n\tType        PositionalEncodingType `json:\"type\"`\n\tMaxSeqLen   int                    `json:\"max_seq_len\"`\n\tHiddenSize  int                    `json:\"hidden_size\"`\n\tHeadDim     int                    `json:\"head_dim,omitempty\"`\n\tBase        float64                `json:\"base\"`\n\tScale       bool                   `json:\"scale\"`\n\tNormalize   bool                   `json:\"normalize\"`\n\tConcatenate bool                   `json:\"concatenate\"`\n\tRotateHalf  bool                   `json:\"rotate_half\"`\n\tUseRoPE     bool                   `json:\"use_rope\"`\n\tUseXPos     bool                   `json:\"use_xpos\"`\n}",
          "symbol_name": "",
          "package_name": "transformer",
          "dependencies": [
            "context",
            "fmt",
            "math",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 198,
          "code_snippet": "   193 | \t}\n   194 | \tif err != nil {\n   195 | \t\treturn nil, fmt.Errorf(\"failed to find Knowledge: %w\", err)\n   196 | \t}\n   197 | \nâ†’  198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \n   203 | \treturn knowledgePtr, nil\n",
          "full_function": "\tknowledge, err := entities.NewKnowledge(name, description)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n\t}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\infrastructure\\persistence\\relational\\postgres_knowledge_repository.go",
          "line_number": 203,
          "code_snippet": "   198 | \tknowledge, err := entities.NewKnowledge(name, description)\n   199 | \tif err != nil {\n   200 | \t\treturn nil, fmt.Errorf(\"failed to create Knowledge entity: %w\", err)\n   201 | \t}\n   202 | \nâ†’  203 | \treturn knowledgePtr, nil\n   204 | }\n   205 | \n   206 | // List lists all Knowledge entities with optional filters\n   207 | func (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n   208 | \tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n",
          "full_function": "\treturn knowledgePtr, nil\n}\n\n// List lists all Knowledge entities with optional filters\nfunc (r *PostgresKnowledgeRepository) List(ctx context.Context, filters *repositories.KnowledgeFilters) ([]*entities.Knowledge, error) {\n\tquery := \"SELECT id, name, description, documents, embeddings, version, created_at, updated_at FROM knowledge WHERE 1=1\"\n\targs := []interface{}{}",
          "symbol_name": "",
          "package_name": "relational",
          "dependencies": [
            "context",
            "database/sql",
            "encoding/json",
            "fmt",
            "time",
            "github.com/vertikon/mcp-core-inventory/internal/domain/entities",
            "github.com/vertikon/mcp-core-inventory/internal/domain/repositories",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 162,
          "code_snippet": "   157 | \tcm.stats.TotalInvalidations++\n   158 | \tcm.stats.InvalidationsByReason[reason]++\n   159 | \tcm.mu.Unlock()\n   160 | \n   161 | \t// Delete from cache\nâ†’  162 | \tcm.cache.Delete(key)\n   163 | \n   164 | \t// Create invalidation event\n   165 | \tevent := \u0026InvalidationEvent{\n   166 | \t\tKey:       key,\n   167 | \t\tReason:    reason,\n",
          "full_function": "func (cm *CoherencyManagerImpl) Invalidate(ctx context.Context, key string, reason string) error {\n\tstart := time.Now()\n\n\tcm.mu.Lock()\n\tcm.stats.TotalInvalidations++\n\tcm.stats.InvalidationsByReason[reason]++\n\tcm.mu.Unlock()\n\n\t// Delete from cache\n\tcm.cache.Delete(key)\n\n\t// Create invalidation event\n\tevent := \u0026InvalidationEvent{\n\t\tKey:       key,\n\t\tReason:    reason,\n\t\tTimestamp: time.Now(),\n\t\tSource:    \"coherency_manager\",\n\t}\n\n\t// Send to invalidation channel\n\tselect {\n\tcase cm.invalidationCh \u003c- event:\n\tdefault:\n\t\tcm.logger.Warn(\"Invalidation channel full, dropping event\",\n\t\t\tzap.String(\"key\", key))\n\t}\n\n\tcm.mu.Lock()\n\tcm.stats.AverageInvalidationTime = time.Since(start)\n\tlastTime := time.Now()\n\tcm.stats.LastInvalidation = \u0026lastTime\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Cache key invalidated\",\n\t\tzap.String(\"key\", key),\n\t\tzap.String(\"reason\", reason))\n\n\treturn nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 217,
          "code_snippet": "   212 | }\n   213 | \n   214 | // Update updates a cache entry\n   215 | func (cm *CoherencyManagerImpl) Update(ctx context.Context, key string, value interface{}) error {\n   216 | \tcm.mu.Lock()\nâ†’  217 | \tcm.stats.TotalUpdates++\n   218 | \tcm.mu.Unlock()\n   219 | \n   220 | \t// Update cache based on strategy\n   221 | \tswitch cm.config.Strategy {\n   222 | \tcase CoherencyStrategyWriteThrough:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 253,
          "code_snippet": "   248 | \t\tStrategy:             cm.config.Strategy,\n   249 | \t\tLevel:                cm.config.Level,\n   250 | \t\tIsCoherent:           true, // Simplified\n   251 | \t\tPendingInvalidations: len(cm.pendingInvalidations),\n   252 | \t\tTotalInvalidations:   cm.stats.TotalInvalidations,\nâ†’  253 | \t\tTotalUpdates:         cm.stats.TotalUpdates,\n   254 | \t}, nil\n   255 | }\n   256 | \n   257 | // GetInvalidationStats returns invalidation statistics\n   258 | func (cm *CoherencyManagerImpl) GetInvalidationStats(ctx context.Context) (*InvalidationStats, error) {\n",
          "full_function": "func (cm *CoherencyManagerImpl) GetCoherencyStatus(ctx context.Context) (*CoherencyStatus, error) {\n\tcm.mu.RLock()\n\tdefer cm.mu.RUnlock()\n\n\treturn \u0026CoherencyStatus{\n\t\tStrategy:             cm.config.Strategy,\n\t\tLevel:                cm.config.Level,\n\t\tIsCoherent:           true, // Simplified\n\t\tPendingInvalidations: len(cm.pendingInvalidations),\n\t\tTotalInvalidations:   cm.stats.TotalInvalidations,\n\t\tTotalUpdates:         cm.stats.TotalUpdates,\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\cache\\cache_coherency.go",
          "line_number": 342,
          "code_snippet": "   337 | \tcm.mu.Lock()\n   338 | \tcm.pendingInvalidations[event.Key] = event\n   339 | \tcm.mu.Unlock()\n   340 | \n   341 | \t// Process invalidation\nâ†’  342 | \tcm.cache.Delete(event.Key)\n   343 | \n   344 | \tcm.mu.Lock()\n   345 | \tdelete(cm.pendingInvalidations, event.Key)\n   346 | \tcm.mu.Unlock()\n   347 | \n",
          "full_function": "func (cm *CoherencyManagerImpl) processInvalidation(event *InvalidationEvent) {\n\tcm.mu.Lock()\n\tcm.pendingInvalidations[event.Key] = event\n\tcm.mu.Unlock()\n\n\t// Process invalidation\n\tcm.cache.Delete(event.Key)\n\n\tcm.mu.Lock()\n\tdelete(cm.pendingInvalidations, event.Key)\n\tcm.mu.Unlock()\n\n\tcm.logger.Debug(\"Invalidation processed\",\n\t\tzap.String(\"key\", event.Key),\n\t\tzap.String(\"reason\", event.Reason))\n}",
          "symbol_name": "",
          "package_name": "cache",
          "dependencies": [
            "context",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 56,
          "code_snippet": "    51 | \t// Verify verifies a signature using RSA\n    52 | \tVerify(data, signature []byte, publicKey *rsa.PublicKey) bool\n    53 | }\n    54 | \n    55 | // Manager implements EncryptionManager\nâ†’   56 | type Manager struct {\n    57 | \tkeyManager KeyManager\n    58 | \tlogger     *zap.Logger\n    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n",
          "full_function": "type Manager struct {\n\tkeyManager KeyManager\n\tlogger     *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 64,
          "code_snippet": "    59 | }\n    60 | \n    61 | // NewEncryptionManager creates a new EncryptionManager\n    62 | func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n    63 | \treturn \u0026Manager{\nâ†’   64 | \t\tkeyManager: keyManager,\n    65 | \t\tlogger:     logger.WithContext(nil),\n    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n",
          "full_function": "func NewEncryptionManager(keyManager KeyManager) EncryptionManager {\n\treturn \u0026Manager{\n\t\tkeyManager: keyManager,\n\t\tlogger:     logger.WithContext(nil),\n\t}\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 71,
          "code_snippet": "    66 | \t}\n    67 | }\n    68 | \n    69 | // Encrypt encrypts data using AES-256-GCM with default key\n    70 | func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\nâ†’   71 | \tkey, err := m.keyManager.GetEncryptionKey()\n    72 | \tif err != nil {\n    73 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    74 | \t\treturn nil, err\n    75 | \t}\n    76 | \treturn m.EncryptWithKey(plaintext, key)\n",
          "full_function": "func (m *Manager) Encrypt(plaintext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.EncryptWithKey(plaintext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\encryption_manager.go",
          "line_number": 81,
          "code_snippet": "    76 | \treturn m.EncryptWithKey(plaintext, key)\n    77 | }\n    78 | \n    79 | // Decrypt decrypts data using AES-256-GCM with default key\n    80 | func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\nâ†’   81 | \tkey, err := m.keyManager.GetEncryptionKey()\n    82 | \tif err != nil {\n    83 | \t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n    84 | \t\treturn nil, err\n    85 | \t}\n    86 | \treturn m.DecryptWithKey(ciphertext, key)\n",
          "full_function": "func (m *Manager) Decrypt(ciphertext []byte) ([]byte, error) {\n\tkey, err := m.keyManager.GetEncryptionKey()\n\tif err != nil {\n\t\tm.logger.Error(\"Failed to get encryption key\", zap.Error(err))\n\t\treturn nil, err\n\t}\n\treturn m.DecryptWithKey(ciphertext, key)\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto",
            "crypto/aes",
            "crypto/cipher",
            "crypto/rand",
            "crypto/rsa",
            "crypto/sha256",
            "errors",
            "io",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap",
            "golang.org/x/crypto/argon2",
            "golang.org/x/crypto/bcrypt"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 52,
          "code_snippet": "    47 | \t// LoadKeyFromFile loads key from file\n    48 | \tLoadKeyFromFile(filePath string) error\n    49 | }\n    50 | \n    51 | // Manager implements KeyManager\nâ†’   52 | type Manager struct {\n    53 | \tencryptionKey []byte\n    54 | \tkeyVersion    string\n    55 | \trsaPrivateKey *rsa.PrivateKey\n    56 | \trsaPublicKey  *rsa.PublicKey\n    57 | \trotationTTL   time.Duration\n",
          "full_function": "type Manager struct {\n\tencryptionKey []byte\n\tkeyVersion    string\n\trsaPrivateKey *rsa.PrivateKey\n\trsaPublicKey  *rsa.PublicKey\n\trotationTTL   time.Duration\n\tlastRotation  time.Time\n\tmu            sync.RWMutex\n\tlogger        *zap.Logger\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\security\\encryption\\certificate_manager.go",
          "line_number": 42,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 72,
          "code_snippet": "    67 | }\n    68 | \n    69 | // NewKeyManager creates a new KeyManager\n    70 | func NewKeyManager(config KeyManagerConfig) KeyManager {\n    71 | \tkm := \u0026Manager{\nâ†’   72 | \t\tkeyVersion:  \"v1\",\n    73 | \t\trotationTTL: config.RotationTTL,\n    74 | \t\tlogger:      logger.WithContext(nil),\n    75 | \t}\n    76 | \n    77 | \t// Generate initial encryption key\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 82,
          "code_snippet": "    77 | \t// Generate initial encryption key\n    78 | \tkey := make([]byte, 32) // AES-256\n    79 | \tif _, err := rand.Read(key); err != nil {\n    80 | \t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n    81 | \t} else {\nâ†’   82 | \t\tkm.encryptionKey = key\n    83 | \t}\n    84 | \n    85 | \t// Generate RSA key pair\n    86 | \tif err := km.generateRSAKeys(config.KeySize); err != nil {\n    87 | \t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n",
          "full_function": "func NewKeyManager(config KeyManagerConfig) KeyManager {\n\tkm := \u0026Manager{\n\t\tkeyVersion:  \"v1\",\n\t\trotationTTL: config.RotationTTL,\n\t\tlogger:      logger.WithContext(nil),\n\t}\n\n\t// Generate initial encryption key\n\tkey := make([]byte, 32) // AES-256\n\tif _, err := rand.Read(key); err != nil {\n\t\tkm.logger.Error(\"Failed to generate encryption key\", zap.Error(err))\n\t} else {\n\t\tkm.encryptionKey = key\n\t}\n\n\t// Generate RSA key pair\n\tif err := km.generateRSAKeys(config.KeySize); err != nil {\n\t\tkm.logger.Error(\"Failed to generate RSA keys\", zap.Error(err))\n\t}\n\n\tkm.lastRotation = time.Now()\n\treturn km\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 96,
          "code_snippet": "    91 | \treturn km\n    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\nâ†’   96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 97,
          "code_snippet": "    92 | }\n    93 | \n    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\nâ†’   97 | \tdefer m.mu.RUnlock()\n    98 | \n    99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\security\\encryption\\key_manager.go",
          "line_number": 99,
          "code_snippet": "    94 | // GetEncryptionKey returns the current encryption key\n    95 | func (m *Manager) GetEncryptionKey() ([]byte, error) {\n    96 | \tm.mu.RLock()\n    97 | \tdefer m.mu.RUnlock()\n    98 | \nâ†’   99 | \tif m.encryptionKey == nil {\n   100 | \t\treturn nil, ErrKeyNotFound\n   101 | \t}\n   102 | \n   103 | \t// Check if rotation is needed\n   104 | \tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n",
          "full_function": "func (m *Manager) GetEncryptionKey() ([]byte, error) {\n\tm.mu.RLock()\n\tdefer m.mu.RUnlock()\n\n\tif m.encryptionKey == nil {\n\t\treturn nil, ErrKeyNotFound\n\t}\n\n\t// Check if rotation is needed\n\tif time.Since(m.lastRotation) \u003e m.rotationTTL {\n\t\tgo m.RotateKey()\n\t}\n\n\t// Return a copy to prevent external modification\n\tkey := make([]byte, len(m.encryptionKey))\n\tcopy(key, m.encryptionKey)\n\treturn key, nil\n}",
          "symbol_name": "",
          "package_name": "encryption",
          "dependencies": [
            "crypto/rand",
            "crypto/rsa",
            "crypto/x509",
            "encoding/base64",
            "encoding/hex",
            "encoding/pem",
            "errors",
            "fmt",
            "os",
            "path/filepath",
            "strings",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 236,
          "code_snippet": "   231 | \t// Compare vector clocks\n   232 | \tcomparison := r.compareVectorClocks(localVC, remoteVC)\n   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\nâ†’  236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\n   238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 238,
          "code_snippet": "   233 | \n   234 | \tswitch comparison {\n   235 | \tcase \"local_greater\":\n   236 | \t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n   237 | \tcase \"remote_greater\":\nâ†’  238 | \t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n   239 | \tcase \"concurrent\":\n   240 | \t\t// Conflict detected, need merge\n   241 | \t\treturn r.resolveCRDTMerge(conflict)\n   242 | \tdefault:\n   243 | \t\t// Same vector clock, use timestamp as tie-breaker\n",
          "full_function": "func (r *ConflictResolverImpl) resolveVectorClock(conflict *Conflict) (*VersionedState, error) {\n\t// Extract vector clocks from metadata\n\tlocalVC := r.getVectorClock(conflict.LocalState)\n\tremoteVC := r.getVectorClock(conflict.RemoteState)\n\n\t// Compare vector clocks\n\tcomparison := r.compareVectorClocks(localVC, remoteVC)\n\n\tswitch comparison {\n\tcase \"local_greater\":\n\t\treturn r.createResolvedState(conflict.LocalState, conflict.RemoteState, \"vector-clock-local\")\n\tcase \"remote_greater\":\n\t\treturn r.createResolvedState(conflict.RemoteState, conflict.LocalState, \"vector-clock-remote\")\n\tcase \"concurrent\":\n\t\t// Conflict detected, need merge\n\t\treturn r.resolveCRDTMerge(conflict)\n\tdefault:\n\t\t// Same vector clock, use timestamp as tie-breaker\n\t\treturn r.resolveLastWriteWins(conflict)\n\t}\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 251,
          "code_snippet": "   246 | }\n   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\nâ†’  251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\n   252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 252,
          "code_snippet": "   247 | \n   248 | // resolveCRDTLastWriterWins resolves conflict using CRDT LWW strategy\n   249 | func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n   250 | \t// CRDT LWW uses timestamps for conflict resolution\n   251 | \tlocalTime := r.getStateTimestamp(conflict.LocalState)\nâ†’  252 | \tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n   253 | \n   254 | \t// Ensure both states have timestamps\n   255 | \tlocalTS := r.ensureTimestamp(conflict.LocalState)\n   256 | \tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n   257 | \n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTLastWriterWins(conflict *Conflict) (*VersionedState, error) {\n\t// CRDT LWW uses timestamps for conflict resolution\n\tlocalTime := r.getStateTimestamp(conflict.LocalState)\n\tremoteTime := r.getStateTimestamp(conflict.RemoteState)\n\n\t// Ensure both states have timestamps\n\tlocalTS := r.ensureTimestamp(conflict.LocalState)\n\tremoteTS := r.ensureTimestamp(conflict.RemoteState)\n\n\tif localTS.After(remoteTS) {\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   conflict.LocalState.Value,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     conflict.LocalState.TTL,\n\t\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t\t}, nil\n\t}\n\n\treturn \u0026VersionedState{\n\t\tKey:     conflict.Key,\n\t\tValue:   conflict.RemoteState.Value,\n\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\tTTL:     conflict.RemoteState.TTL,\n\t\tMeta:    r.mergeCRDTMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta, localTS, remoteTS),\n\t}, nil\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 283,
          "code_snippet": "   278 | func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n   279 | \t// For simple values, use last-write-wins\n   280 | \t// For complex values (maps, sets, counters), perform actual CRDT merge\n   281 | \n   282 | \t// Check if values are mergeable\nâ†’  283 | \tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n   284 | \t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n   285 | \t\tif err != nil {\n   286 | \t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n   287 | \t\t\t\tzap.String(\"key\", conflict.Key),\n   288 | \t\t\t\tzap.Error(err))\n",
          "full_function": "func (r *ConflictResolverImpl) resolveCRDTMerge(conflict *Conflict) (*VersionedState, error) {\n\t// For simple values, use last-write-wins\n\t// For complex values (maps, sets, counters), perform actual CRDT merge\n\n\t// Check if values are mergeable\n\tif r.isMergeableValue(conflict.LocalState.Value, conflict.RemoteState.Value) {\n\t\tmergedValue, err := r.mergeValues(conflict.LocalState.Value, conflict.RemoteState.Value)\n\t\tif err != nil {\n\t\t\tr.logger.Error(\"CRDT merge failed, falling back to LWW\",\n\t\t\t\tzap.String(\"key\", conflict.Key),\n\t\t\t\tzap.Error(err))\n\t\t\treturn r.resolveCRDTLastWriterWins(conflict)\n\t\t}\n\n\t\treturn \u0026VersionedState{\n\t\t\tKey:     conflict.Key,\n\t\t\tValue:   mergedValue,\n\t\t\tVersion: max(conflict.LocalState.Version, conflict.RemoteState.Version) + 1,\n\t\t\tTTL:     r.mergeTTL(conflict.LocalState.TTL, conflict.RemoteState.TTL),\n\t\t\tMeta:    r.createCRDTMergeMeta(conflict.LocalState.Meta, conflict.RemoteState.Meta),\n\t\t}, nil\n\t}\n\n\t// Non-mergeable, fall back to LWW\n\treturn r.resolveCRDTLastWriterWins(conflict)\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 396,
          "code_snippet": "   391 | \treturn ts\n   392 | }\n   393 | \n   394 | func (r *ConflictResolverImpl) isMergeableValue(value interface{}) bool {\n   395 | \t// Check if value is a type that can be merged\nâ†’  396 | \tswitch v := value.(type) {\n   397 | \tcase map[string]interface{}:\n   398 | \t\treturn true\n   399 | \tcase []interface{}:\n   400 | \t\treturn true\n   401 | \tcase map[string]string:\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 415,
          "code_snippet": "   410 | func (r *ConflictResolverImpl) mergeValues(local, remote interface{}) (interface{}, error) {\n   411 | \t// Implement actual CRDT merge logic based on value type\n   412 | \tswitch l := local.(type) {\n   413 | \tcase map[string]interface{}:\n   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\nâ†’  415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\n   419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 419,
          "code_snippet": "   414 | \t\tif r, ok := remote.(map[string]interface{}); ok {\n   415 | \t\t\treturn r.mergeMaps(l, r), nil\n   416 | \t\t}\n   417 | \tcase []interface{}:\n   418 | \t\tif r, ok := remote.([]interface{}); ok {\nâ†’  419 | \t\t\treturn r.mergeArrays(l, r), nil\n   420 | \t\t}\n   421 | \t}\n   422 | \n   423 | \t// Cannot merge, return error\n   424 | \treturn nil, fmt.Errorf(\"values are not mergeable\")\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 622,
          "code_snippet": "   617 | \t\treturn a\n   618 | \t}\n   619 | \treturn b\n   620 | }\n   621 | \nâ†’  622 | func max(a, b time.Time) time.Time {\n   623 | \tif a.After(b) {\n   624 | \t\treturn a\n   625 | \t}\n   626 | \treturn b\n   627 | }\n",
          "full_function": "func max(a, b time.Time) time.Time {\n\tif a.After(b) {\n\t\treturn a\n\t}\n\treturn b\n}",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\\tinternal\\state\\store\\conflict_resolver.go",
          "line_number": 615,
          "code_snippet": "",
          "full_function": "",
          "symbol_name": "",
          "package_name": "",
          "dependencies": null,
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\store\\conflict_resolver.go",
          "line_number": 516,
          "code_snippet": "   511 | \n   512 | \t// Add CRDT-specific metadata\n   513 | \tmerged[\"crdt_strategy\"] = \"last-writer-wins\"\n   514 | \tmerged[\"local_timestamp\"] = localTS\n   515 | \tmerged[\"remote_timestamp\"] = remoteTS\nâ†’  516 | \tmerged[\"winner_timestamp\"] = max(localTS, remoteTS)\n   517 | \n   518 | \treturn merged\n   519 | }\n   520 | \n   521 | func (r *ConflictResolverImpl) createCRDTMergeMeta(local, remote map[string]interface{}) map[string]interface{} {\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "store",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 249,
          "code_snippet": "   244 | }\n   245 | \n   246 | // ReplayFromSnapshot replays events from a snapshot version\n   247 | func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n   248 | \t// Get snapshot\nâ†’  249 | \tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n   250 | \tif err != nil {\n   251 | \t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n   252 | \t}\n   253 | \n   254 | \t// Get events after snapshot version\n",
          "full_function": "func (er *EventReplayImpl) ReplayFromSnapshot(ctx context.Context, aggregateID string, snapshotVersion int64, handler ReplayHandler) (*ReplayProgress, error) {\n\t// Get snapshot\n\tsnapshot, err := er.store.GetSnapshot(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get snapshot: %w\", err)\n\t}\n\n\t// Get events after snapshot version\n\tevents, err := er.store.GetEvents(ctx, aggregateID, snapshotVersion+1, 0)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get events after snapshot: %w\", err)\n\t}\n\n\tif len(events) == 0 {\n\t\treturn \u0026ReplayProgress{\n\t\t\tTotalEvents:     0,\n\t\t\tProcessedEvents: 0,\n\t\t\tIsComplete:      true,\n\t\t}, nil\n\t}\n\n\tstartTime := time.Now()\n\tprogress := \u0026ReplayProgress{\n\t\tTotalEvents:    int64(len(events)),\n\t\tStartTime:      startTime,\n\t\tCurrentVersion: snapshotVersion + 1,\n\t}\n\n\terr = er.replaySequential(ctx, events, handler, progress)\n\tprogress.ElapsedTime = time.Since(startTime)\n\tprogress.IsComplete = true\n\n\tif err != nil {\n\t\tprogress.LastError = err.Error()\n\t\treturn progress, err\n\t}\n\n\treturn progress, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_replay.go",
          "line_number": 290,
          "code_snippet": "   285 | }\n   286 | \n   287 | // ReplayToState replays events to rebuild state at a specific version\n   288 | func (er *EventReplayImpl) ReplayToState(ctx context.Context, aggregateID string, targetVersion int64, handler ReplayHandler) (interface{}, error) {\n   289 | \t// Get all events up to target version\nâ†’  290 | \tevents, err := er.store.GetEvents(ctx, aggregateID, 1, targetVersion)\n   291 | \tif err != nil {\n   292 | \t\treturn nil, fmt.Errorf(\"failed to get events: %w\", err)\n   293 | \t}\n   294 | \n   295 | \t// Replay events\n",
          "full_function": "",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 140,
          "code_snippet": "   135 | \tif exists {\n   136 | \t\t// Return copy\n   137 | \t\tcopy := *versionInfo\n   138 | \t\tif versionInfo.VersionHistory != nil {\n   139 | \t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\nâ†’  140 | \t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n   141 | \t\t}\n   142 | \t\treturn \u0026copy, nil\n   143 | \t}\n   144 | \n   145 | \t// Load from event store\n",
          "full_function": "func (ev *EventVersioningImpl) GetVersion(ctx context.Context, aggregateID string) (*VersionInfo, error) {\n\tev.mu.RLock()\n\tversionInfo, exists := ev.versions[aggregateID]\n\tev.mu.RUnlock()\n\n\tif exists {\n\t\t// Return copy\n\t\tcopy := *versionInfo\n\t\tif versionInfo.VersionHistory != nil {\n\t\t\tcopy.VersionHistory = make([]VersionHistoryEntry, len(versionInfo.VersionHistory))\n\t\t\tcopy(versionInfo.VersionHistory, copy.VersionHistory)\n\t\t}\n\t\treturn \u0026copy, nil\n\t}\n\n\t// Load from event store\n\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t}\n\n\tversionInfo = \u0026VersionInfo{\n\t\tAggregateID:    aggregateID,\n\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\tCurrentVersion: aggregateInfo.Version,\n\t\tMetadata:       make(map[string]interface{}),\n\t}\n\n\tif ev.config.EnableHistory {\n\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t}\n\n\tev.mu.Lock()\n\tev.versions[aggregateID] = versionInfo\n\tev.mu.Unlock()\n\n\treturn versionInfo, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        },
        {
          "file_path": "E:\\vertikon\\.endurance\\internal\\services\\bloco-1-core\\mcp-core-inventory\\internal\\state\\events\\event_versioning.go",
          "line_number": 216,
          "code_snippet": "   211 | \t\tif ev.config.ConflictResolution == \"reject\" {\n   212 | \t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n   213 | \t\t}\n   214 | \n   215 | \t\t// Resolve conflict\nâ†’  216 | \t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n   217 | \t\tif err != nil {\n   218 | \t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n   219 | \t\t}\n   220 | \n   221 | \t\tnewVersion = resolvedVersion\n",
          "full_function": "func (ev *EventVersioningImpl) IncrementVersion(ctx context.Context, aggregateID string, event *Event) (int64, error) {\n\tev.mu.Lock()\n\tdefer ev.mu.Unlock()\n\n\tversionInfo, exists := ev.versions[aggregateID]\n\tif !exists {\n\t\t// Load from store\n\t\taggregateInfo, err := ev.store.GetAggregateInfo(ctx, aggregateID)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to get aggregate info: %w\", err)\n\t\t}\n\n\t\tversionInfo = \u0026VersionInfo{\n\t\t\tAggregateID:    aggregateID,\n\t\t\tAggregateType:  aggregateInfo.AggregateType,\n\t\t\tCurrentVersion: aggregateInfo.Version,\n\t\t\tMetadata:       make(map[string]interface{}),\n\t\t}\n\n\t\tif ev.config.EnableHistory {\n\t\t\tversionInfo.VersionHistory = make([]VersionHistoryEntry, 0)\n\t\t}\n\n\t\tev.versions[aggregateID] = versionInfo\n\t}\n\n\t// Increment version\n\tnewVersion := versionInfo.CurrentVersion + 1\n\n\t// Validate version continuity\n\tif event.Version != 0 \u0026\u0026 event.Version != newVersion {\n\t\tconflict := \u0026VersionConflict{\n\t\t\tAggregateID:     aggregateID,\n\t\t\tExpectedVersion: newVersion,\n\t\t\tActualVersion:   event.Version,\n\t\t\tConflictTime:    time.Now(),\n\t\t}\n\n\t\tev.stats.TotalConflicts++\n\t\tev.conflicts[aggregateID] = append(ev.conflicts[aggregateID], conflict)\n\n\t\tif ev.config.ConflictResolution == \"reject\" {\n\t\t\treturn 0, fmt.Errorf(\"version conflict: expected %d, got %d\", newVersion, event.Version)\n\t\t}\n\n\t\t// Resolve conflict\n\t\tresolvedVersion, err := ev.resolveVersionConflict(ctx, conflict)\n\t\tif err != nil {\n\t\t\treturn 0, fmt.Errorf(\"failed to resolve conflict: %w\", err)\n\t\t}\n\n\t\tnewVersion = resolvedVersion\n\t\tconflict.Resolution = fmt.Sprintf(\"resolved to %d\", resolvedVersion)\n\t\tev.stats.ResolvedConflicts++\n\t}\n\n\t// Update version info\n\tversionInfo.CurrentVersion = newVersion\n\tversionInfo.LastEventID = event.ID\n\tversionInfo.LastEventTime = event.Timestamp\n\n\t// Add to history\n\tif ev.config.EnableHistory {\n\t\tentry := VersionHistoryEntry{\n\t\t\tVersion:   newVersion,\n\t\t\tEventID:   event.ID,\n\t\t\tTimestamp: event.Timestamp,\n\t\t\tEventType: event.Type,\n\t\t}\n\n\t\tversionInfo.VersionHistory = append(versionInfo.VersionHistory, entry)\n\n\t\t// Trim history if needed\n\t\tif len(versionInfo.VersionHistory) \u003e ev.config.HistoryRetention {\n\t\t\tversionInfo.VersionHistory = versionInfo.VersionHistory[len(versionInfo.VersionHistory)-ev.config.HistoryRetention:]\n\t\t}\n\t}\n\n\t// Update statistics\n\tev.stats.TotalVersions++\n\tev.stats.VersionDistribution[newVersion]++\n\n\tev.logger.Debug(\"Version incremented\",\n\t\tzap.String(\"aggregate_id\", aggregateID),\n\t\tzap.Int64(\"version\", newVersion))\n\n\treturn newVersion, nil\n}",
          "symbol_name": "",
          "package_name": "events",
          "dependencies": [
            "context",
            "fmt",
            "sync",
            "time",
            "github.com/vertikon/mcp-core-inventory/pkg/logger",
            "go.uber.org/zap"
          ],
          "related_files": null
        }
      ],
      "impact_analysis": {
        "severity": "critical",
        "affected_files": 25,
        "affected_lines": 83,
        "blocks_deploy": true,
        "blocks_tests": false,
        "breaks_api": false,
        "estimated_time": "1-2 horas",
        "priority": 1,
        "risk_level": "high",
        "dependencies": null
      },
      "related_gaps": null,
      "tags": [],
      "error_breakdown": {},
      "top_files": []
    }
  ],
  "technical_debt": null,
  "recommended_tools": [
    {
      "tool_name": "golangci-lint",
      "install_command": "go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest",
      "diagnose_command": "golangci-lint run",
      "fix_command": "# NAO use --fix automaticamente, revise cada issue",
      "config_required": true,
      "config_template": ".golangci.yml com linters selecionados",
      "documentation": "https://golangci-lint.run/",
      "alternative_tools": null
    },
    {
      "tool_name": "staticcheck",
      "install_command": "go install honnef.co/go/tools/cmd/staticcheck@latest",
      "diagnose_command": "staticcheck ./...",
      "fix_command": "# Manual - staticcheck nao tem auto-fix",
      "config_required": false,
      "config_template": "",
      "documentation": "https://staticcheck.io/",
      "alternative_tools": null
    },
    {
      "tool_name": "gosec",
      "install_command": "go install github.com/securego/gosec/v2/cmd/gosec@latest",
      "diagnose_command": "gosec ./...",
      "fix_command": "# Manual - corrija issues de seguranca",
      "config_required": false,
      "config_template": "",
      "documentation": "https://github.com/securego/gosec",
      "alternative_tools": null
    }
  ],
  "next_steps": [
    "ðŸ”´ URGENTE: Resolver 2 bloqueador(es)"
  ],
  "estimated_effort": "2h30m"
}